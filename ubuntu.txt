Env preparation

1. sudo apt install git-lfs
2. sudo apt-get install cuda-toolkit-12-8
3. nano ~/.bashrc
4. add
export PATH=/usr/local/cuda-12.8/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-12.8/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
export CUDA_HOME=/usr/local/cuda-12.8
export PATH=$PATH:/home/ubuntu/.local/bin
to the end of the file
5. source ~/.bashrc

Download libs
1. pip install ninja
2. pip install torch==2.6.0
3. pip install flash_attn==2.7.0.post2 --no-build-isolation
3. pip install -r requirements

Run inference

python3 -m marti.cli.commands.test_new --config-name ma_chain \
  default_agent.pretrain="/data/Qwen2.5-3B" \
  default_agent.vllm_num_engines=1 \
  default_agent.prompt_max_len=7000 \
  default_agent.generate_max_len=1000 \
  default_agent.temperature=0.6 \
  default_agent.rollout_batch_size=64 \
  default_agent.micro_rollout_batch_size=1 \
  default_agent.save_path="$(pwd)/results/ma_chain/Qwen2.5-3B/AMC" \
  prompt_data="json@$(pwd)/data/AMC" \
  input_key="problem" \
  label_key="answer" \
  add_prompt_suffix=""

To run GRPO on single agents
1. pip install -U "ray[default]"