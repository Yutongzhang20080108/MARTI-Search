2025-08-10 14:46:54,084	INFO dashboard_sdk.py:338 -- Uploading package gcs://_ray_pkg_cded4ab91115b0ee.zip.
2025-08-10 14:46:54,085	INFO packaging.py:575 -- Creating a file package for local module '/data/MARTI-Search'.
[37mJob submission server address[39m: [1mhttp://localhost:8265[22m

[32m-------------------------------------------------------[39m
[32mJob 'raysubmit_1FGJFiyXkBEXRuzy' submitted successfully[39m
[32m-------------------------------------------------------[39m

[36mNext steps[39m
  Query the logs of the job:
    [1mray job logs raysubmit_1FGJFiyXkBEXRuzy[22m
  Query the status of the job:
    [1mray job status raysubmit_1FGJFiyXkBEXRuzy[22m
  Request the job to be stopped:
    [1mray job stop raysubmit_1FGJFiyXkBEXRuzy[22m

Tailing logs until the job exits (disable with --no-wait):
2025-08-10 14:46:54,214	INFO job_manager.py:530 -- Runtime env is setting up.
[2025-08-10 14:47:05,880] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO 08-10 14:47:08 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 08-10 14:47:08 [__init__.py:239] Automatically detected platform cuda.
/home/ubuntu/.local/lib/python3.10/site-packages/class_registry/entry_points.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import iter_entry_points
[Warning] Please --flash_attn to accelerate when --packing_samples is enabled.
parallel_loading: true
agent_workflow: multi-agents-debate
agent_func_path: null
workflow_version: new
shared_agents: false
credit_ref_num_nodes: 1
credit_ref_num_gpus_per_node: 8
credit_num_nodes: 1
credit_num_gpus_per_node: 8
colocate_credit_ref: false
credit_beta: 0.05
credit_granularity: token
credit_nll_loss: false
credit_nll_loss_coef: 0.0
credit_grad_clip: 10.0
credit_adam_betas:
- 0.9
- 0.95
credit_l2: 0.0
credit_score_type: process
credit_learning_rate: 1.0e-06
credit_pretrain: null
credit_scheduler: constant_with_warmup
credit_lr_warmup_ratio: 0.0
credit_batch_norm: false
credit_model: null
warmup_steps_for_credit: -1
credit_score_coef: 1.0
verifier_score_coef: 1.0
reward_alloc:
  name: margin
  alpha: 0.5
  beta: 0.5
  use_ttrl: false
allow_label_list: false
separate_label_list: null
mask_truncated_completions: true
eval_before_training: true
eval_only: false
eval_workers: -1
default_agent:
  pg_strategy: SPREAD
  role: base
  is_reasoning_model: false
  enable_thinking: false
  is_tuning: true
  pretrain: /data/Qwen2.5-3B
  reward_pretrain: null
  remote_rm_url: null
  critic_pretrain: null
  value_head_prefix: score
  ref_reward_offload: false
  ref_num_nodes: 1
  ref_num_gpus_per_node: 2
  reward_num_nodes: 1
  reward_num_gpus_per_node: 8
  colocate_actor_ref: false
  colocate_all_models: true
  actor_num_nodes: 1
  actor_num_gpus_per_node: 2
  critic_num_nodes: 1
  critic_num_gpus_per_node: 2
  colocate_critic_reward: false
  vllm_num_engines: 2
  vllm_tensor_parallel_size: 1
  vllm_sync_backend: nccl
  vllm_gpu_memory_utilization: 0.6
  vllm_enable_sleep: true
  deepspeed_enable_sleep: true
  enable_prefix_caching: false
  enforce_eager: false
  eval_steps: 5
  logging_steps: 1
  save_steps: 1000
  ckpt_path: /data/MARTI-Search/outputs/reinforce-mad-3x2-unshared//0810/Qwen2.5-3B/ckpt
  max_ckpt_num: 100
  max_ckpt_mem: 100000000
  load_checkpoint: false
  local_rank: -1
  zero_stage: 3
  gradient_checkpointing: true
  bf16: true
  enable_ema: false
  zpg: 1
  adam_offload: true
  actor_init_on_gpu: false
  flash_attn: false
  grad_accum_dtype: null
  disable_trace_cache: false
  gradient_checkpointing_use_reentrant: false
  disable_fast_tokenizer: false
  load_in_4bit: false
  lora_rank: 0
  lora_alpha: 16
  target_modules: all-linear
  lora_dropout: 0.0
  save_path: /data/MARTI-Search/outputs/reinforce-mad-3x2-unshared/0810/Qwen2.5-3B/model
  num_episodes: 5
  rollout_batch_size: 128
  micro_rollout_batch_size: 8
  max_epochs: 1
  max_len: null
  prompt_max_len: 12288
  generate_max_len: 4096
  truncate_prompt: false
  max_samples: 400000
  max_norm: 1.0
  l2: 0.0
  ptx_coef: 0.05
  eps_clip: 0.2
  value_clip: 0.2
  lambd: 1.0
  gamma: 1.0
  micro_train_batch_size: 4
  train_batch_size: 128
  normalize_reward: true
  top_p: 1.0
  temperature: 1.0
  eval_temperature: 0.0
  seed: 42
  freezing_actor_steps: -1
  n_samples_per_prompt: 8
  save_value_network: false
  use_kl_loss: true
  actor_learning_rate: 1.0e-06
  critic_learning_rate: 9.0e-06
  lr_warmup_ratio: 0.03
  lr_warmup_steps: null
  kl_target: null
  init_kl_coef: 0.0
  use_kl_estimator_k3: false
  aux_loss_coef: 0.0
  adam_betas:
  - 0.9
  - 0.95
  reward_clip_range:
  - -10
  - 10
  advantage_estimator: reinforce
  no_advantage_std_norm: false
  training_mode: rl
  eos_token: null
packing_samples: true
extra_eval_tasks:
- aime
- amc
extra_eval_dir: /data/MARTI-Search/data/Bench
verify_task: math
verify_task_eval: math
filter_samples_by_reward: false
prompt_data: json@/data/MARTI-Search/data/MATH
prompt_data_probs: '1.0'
prompt_split: train
pretrain_data: null
pretrain_data_probs: '1.0'
pretrain_split: train
input_key: prompt
label_key: answer
output_key: output
metadata_key: metadata
add_think_token: 0
add_prompt_suffix: null
input_template: null
apply_chat_template: false
use_wandb: 135ccccf711bb2b3c1fc414b571925eda93cbb38
wandb_org: null
wandb_group: null
wandb_project: MARTI
wandb_run_name: 0810-MATH-Qwen2.5-3B-reinforce-mad-3x2-unshared
use_tensorboard: /data/MARTI-Search/logs/reinforce-mad-3x2-unshared-0810-Qwen2.5-3B
perf: false
async_workflow: false
workflow_func_path: null
processor_func_path: null
tools_config:
  num_workers: 128
  max_concurrent_calls: 8
  enable_metrics: true
  enable_rate_limiting: true
  rate_limit: 8
workflow_args:
  template_id: 1
  num_rounds: 2
  max_others: 5
  contain_self: true
  shuffle_responses: true
chat_template:
- '$question


  Please reason step by step, and put your final answer within \boxed{}.'
- 'Here are solutions from other agents:

  $responses_str


  Using these responses as additional advice, can you give an updated bullet by bullet
  answer to the following question:

  $question


  Please reason step by step, and put your final answer within \boxed{}.'
agents:
- generator_1:
    role: generator
- generator_2:
    role: generator
- generator_3:
    role: generator
pg_strategy: SPREAD
role: base
is_reasoning_model: false
enable_thinking: false
is_tuning: true
pretrain: /data/Qwen2.5-3B
reward_pretrain: null
remote_rm_url: null
critic_pretrain: null
value_head_prefix: score
ref_reward_offload: false
ref_num_nodes: 1
ref_num_gpus_per_node: 2
reward_num_nodes: 1
reward_num_gpus_per_node: 8
colocate_actor_ref: false
colocate_all_models: true
actor_num_nodes: 1
actor_num_gpus_per_node: 2
critic_num_nodes: 1
critic_num_gpus_per_node: 2
colocate_critic_reward: false
vllm_num_engines: 2
vllm_tensor_parallel_size: 1
vllm_sync_backend: nccl
vllm_gpu_memory_utilization: 0.6
vllm_enable_sleep: true
deepspeed_enable_sleep: true
enable_prefix_caching: false
enforce_eager: false
eval_steps: 5
logging_steps: 1
save_steps: 1000
ckpt_path: /data/MARTI-Search/outputs/reinforce-mad-3x2-unshared//0810/Qwen2.5-3B/ckpt
max_ckpt_num: 100
max_ckpt_mem: 100000000
load_checkpoint: false
local_rank: -1
zero_stage: 3
gradient_checkpointing: true
bf16: true
enable_ema: false
zpg: 1
adam_offload: true
actor_init_on_gpu: false
flash_attn: true
grad_accum_dtype: null
disable_trace_cache: false
gradient_checkpointing_use_reentrant: false
disable_fast_tokenizer: false
load_in_4bit: false
lora_rank: 0
lora_alpha: 16
target_modules: all-linear
lora_dropout: 0.0
save_path: /data/MARTI-Search/outputs/reinforce-mad-3x2-unshared/0810/Qwen2.5-3B/model
num_episodes: 5
rollout_batch_size: 128
micro_rollout_batch_size: 8
max_epochs: 1
max_len: null
prompt_max_len: 12288
generate_max_len: 4096
truncate_prompt: false
max_samples: 400000
max_norm: 1.0
l2: 0.0
ptx_coef: 0.05
eps_clip: 0.2
value_clip: 0.2
lambd: 1.0
gamma: 1.0
micro_train_batch_size: 4
train_batch_size: 128
normalize_reward: true
top_p: 1.0
temperature: 1.0
eval_temperature: 0.0
seed: 42
freezing_actor_steps: -1
n_samples_per_prompt: 8
save_value_network: false
use_kl_loss: true
actor_learning_rate: 1.0e-06
critic_learning_rate: 9.0e-06
lr_warmup_ratio: 0.03
lr_warmup_steps: null
kl_target: null
init_kl_coef: 0.0
use_kl_estimator_k3: false
aux_loss_coef: 0.0
adam_betas:
- 0.9
- 0.95
reward_clip_range:
- -10
- 10
advantage_estimator: reinforce
no_advantage_std_norm: false
training_mode: rl
eos_token: null

dataset: json@/data/MARTI-Search/data/MATH
loaded json from files
[Dataset({
    features: ['prompt', 'answer', 'source', 'id'],
    num_rows: 8890
})]
Dataset({
    features: ['prompt', 'answer', 'source', 'id'],
    num_rows: 8890
})

Preprocessing data:   0%|          | 0/8890 [00:00<?, ?it/s]
Preprocessing data:  20%|██        | 1817/8890 [00:00<00:00, 18162.92it/s]
Preprocessing data:  42%|████▏     | 3715/8890 [00:00<00:00, 18639.51it/s]
Preprocessing data:  64%|██████▎   | 5662/8890 [00:00<00:00, 19018.17it/s]
Preprocessing data:  85%|████████▌ | 7564/8890 [00:00<00:00, 19007.48it/s]
Preprocessing data: 100%|██████████| 8890/8890 [00:00<00:00, 18833.39it/s]
{'prompt': 'There are 5 blue chips and 3 yellow chips in a bag. One chip is drawn from the bag. That chip is placed back into the bag. A second chip is then drawn. What is the probability that the two selected chips are of different colors? Express your answer as a common fraction.', 'label': '\\frac{15}{32}', 'indice': 1197, 'metadata': '{}'}
====================
{'prompt': 'Let $C$ be the circle with equation $x^2+2y-9=-y^2+18x+9$. If $(a,b)$ is the center of $C$ and $r$ is its radius, what is the value of $a+b+r$?', 'label': '18', 'indice': 4196, 'metadata': '{}'}
====================
Dataset({
    features: ['prompt', 'answer', 'source', 'id'],
    num_rows: 500
})

Preprocessing data:   0%|          | 0/500 [00:00<?, ?it/s]
Preprocessing data: 100%|██████████| 500/500 [00:00<00:00, 18087.63it/s]
{'prompt': 'What is the smallest number which is one less than twice its reciprocal?', 'label': '-2', 'indice': 341, 'metadata': '{}'}
====================
{'prompt': 'Compute $\\arcsin \\left( -\\frac{1}{2} \\right).$  Express your answer in radians.', 'label': '-\\frac{\\pi}{6}', 'indice': 53, 'metadata': '{}'}
====================
Dataset({
    features: ['prompt', 'answer', 'source', 'id'],
    num_rows: 30
})

Preprocessing data:   0%|          | 0/30 [00:00<?, ?it/s]
Preprocessing data: 100%|██████████| 30/30 [00:00<00:00, 17832.93it/s]
{'prompt': 'Torus $T$ is the surface produced by revolving a circle with radius $3$ around an axis in the plane of the circle that is a distance $6$ from the center of the circle (so like a donut). Let $S$ be a sphere with a radius $11$. When $T$ rests on the inside of $S$, it is internally tangent to $S$ along a circle with radius $r_i$, and when $T$ rests on the outside of $S$, it is externally tangent to $S$ along a circle with radius $r_o$. The difference $r_i-r_o$ can be written as $\\tfrac{m}{n}$, where $m$ and $n$ are relatively prime positive integers. Find $m+n$.\n[asy] unitsize(0.3 inch); draw(ellipse((0,0), 3, 1.75)); draw((-1.2,0.1)..(-0.8,-0.03)..(-0.4,-0.11)..(0,-0.15)..(0.4,-0.11)..(0.8,-0.03)..(1.2,0.1)); draw((-1,0.04)..(-0.5,0.12)..(0,0.16)..(0.5,0.12)..(1,0.04)); draw((0,2.4)--(0,-0.15)); draw((0,-0.15)--(0,-1.75), dashed); draw((0,-1.75)--(0,-2.25)); draw(ellipse((2,0), 1, 0.9)); draw((2.03,-0.02)--(2.9,-0.4)); [/asy]', 'label': '127', 'indice': 22, 'metadata': '{}'}
====================
{'prompt': 'Let $N$ be the greatest four-digit positive integer with the property that whenever one of its digits is changed to $1$, the resulting number is divisible by $7$. Let $Q$ and $R$ be the quotient and remainder, respectively, when $N$ is divided by $1000$. Find $Q+R$.', 'label': '699', 'indice': 21, 'metadata': '{}'}
====================
Dataset({
    features: ['prompt', 'answer', 'source', 'id'],
    num_rows: 83
})

Preprocessing data:   0%|          | 0/83 [00:00<?, ?it/s]
Preprocessing data: 100%|██████████| 83/83 [00:00<00:00, 10844.07it/s]
{'prompt': 'Suppose that $13$ cards numbered $1, 2, 3, \\ldots, 13$ are arranged in a row. The task is to pick them up in numerically increasing order, working repeatedly from left to right. In the example below, cards $1, 2, 3$ are picked up on the first pass, $4$ and $5$ on the second pass, $6$ on the third pass, $7, 8, 9, 10$ on the fourth pass, and $11, 12, 13$ on the fifth pass. For how many of the $13!$ possible orderings of the cards will the $13$ cards be picked up in exactly two passes?', 'label': '8178', 'indice': 10, 'metadata': '{}'}
====================
{'prompt': 'For complex number $u = a+bi$ and $v = c+di$ (where $i=\\sqrt{-1}$), define the binary operation\n$u \\otimes v = ac + bdi$\nSuppose $z$ is a complex number such that $z\\otimes z = z^{2}+40$. What is $|z|^2$?', 'label': '50', 'indice': 68, 'metadata': '{}'}
====================
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: No netrc file found, creating one.
wandb: Appending key for api.wandb.ai to your netrc file: /home/ubuntu/.netrc
wandb: Currently logged in as: yutongzhang (GreatResearchTakesTime) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /tmp/ray/session_2025-08-10_14-42-42_399116_1072534/runtime_resources/working_dir_files/_ray_pkg_cded4ab91115b0ee/wandb/run-20250810_144712-ea5mzyg4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 0810-MATH-Qwen2.5-3B-reinforce-mad-3x2-unshared
wandb: ⭐️ View project at https://wandb.ai/GreatResearchTakesTime/MARTI
wandb: 🚀 View run at https://wandb.ai/GreatResearchTakesTime/MARTI/runs/ea5mzyg4
Credit model is not supported for Multi-Agents-Debate and Mixture-of-Agents. Set Credit model to None.
Create agent forCreate agent for Create agent for generator_1generator_2   generator_3{'role': 'generator'}{'role': 'generator'} 

{'role': 'generator'}generator_1generator_2
  {'role': 'generator', 'pg_strategy': 'SPREAD', 'is_reasoning_model': False, 'enable_thinking': False, 'is_tuning': True, 'pretrain': '/data/Qwen2.5-3B', 'reward_pretrain': None, 'remote_rm_url': None, 'critic_pretrain': None, 'value_head_prefix': 'score', 'ref_reward_offload': False, 'ref_num_nodes': 1, 'ref_num_gpus_per_node': 2, 'reward_num_nodes': 1, 'reward_num_gpus_per_node': 8, 'colocate_actor_ref': False, 'colocate_all_models': True, 'actor_num_nodes': 1, 'actor_num_gpus_per_node': 2, 'critic_num_nodes': 1, 'critic_num_gpus_per_node': 2, 'colocate_critic_reward': False, 'vllm_num_engines': 2, 'vllm_tensor_parallel_size': 1, 'vllm_sync_backend': 'nccl', 'vllm_gpu_memory_utilization': 0.6, 'vllm_enable_sleep': True, 'deepspeed_enable_sleep': True, 'enable_prefix_caching': False, 'enforce_eager': False, 'eval_steps': 5, 'logging_steps': 1, 'save_steps': 1000, 'ckpt_path': '/data/MARTI-Search/outputs/reinforce-mad-3x2-unshared//0810/Qwen2.5-3B/ckpt', 'max_ckpt_num': 100, 'max_ckpt_mem': 100000000, 'load_checkpoint': False, 'local_rank': -1, 'zero_stage': 3, 'gradient_checkpointing': True, 'bf16': True, 'enable_ema': False, 'zpg': 1, 'adam_offload': True, 'actor_init_on_gpu': False, 'flash_attn': False, 'grad_accum_dtype': None, 'disable_trace_cache': False, 'gradient_checkpointing_use_reentrant': False, 'disable_fast_tokenizer': False, 'load_in_4bit': False, 'lora_rank': 0, 'lora_alpha': 16, 'target_modules': 'all-linear', 'lora_dropout': 0.0, 'save_path': '/data/MARTI-Search/outputs/reinforce-mad-3x2-unshared/0810/Qwen2.5-3B/model', 'num_episodes': 5, 'rollout_batch_size': 128, 'micro_rollout_batch_size': 8, 'max_epochs': 1, 'max_len': None, 'prompt_max_len': 12288, 'generate_max_len': 4096, 'truncate_prompt': False, 'max_samples': 400000, 'max_norm': 1.0, 'l2': 0.0, 'ptx_coef': 0.05, 'eps_clip': 0.2, 'value_clip': 0.2, 'lambd': 1.0, 'gamma': 1.0, 'micro_train_batch_size': 4, 'train_batch_size': 128, 'normalize_reward': True, 'top_p': 1.0, 'temperature': 1.0, 'eval_temperature': 0.0, 'seed': 42, 'freezing_actor_steps': -1, 'n_samples_per_prompt': 8, 'save_value_network': False, 'use_kl_loss': True, 'actor_learning_rate': 1e-06, 'critic_learning_rate': 9e-06, 'lr_warmup_ratio': 0.03, 'lr_warmup_steps': None, 'kl_target': None, 'init_kl_coef': 0.0, 'use_kl_estimator_k3': False, 'aux_loss_coef': 0.0, 'adam_betas': [0.9, 0.95], 'reward_clip_range': [-10, 10], 'advantage_estimator': 'reinforce', 'no_advantage_std_norm': False, 'training_mode': 'rl', 'eos_token': None}{'role': 'generator', 'pg_strategy': 'SPREAD', 'is_reasoning_model': False, 'enable_thinking': False, 'is_tuning': True, 'pretrain': '/data/Qwen2.5-3B', 'reward_pretrain': None, 'remote_rm_url': None, 'critic_pretrain': None, 'value_head_prefix': 'score', 'ref_reward_offload': False, 'ref_num_nodes': 1, 'ref_num_gpus_per_node': 2, 'reward_num_nodes': 1, 'reward_num_gpus_per_node': 8, 'colocate_actor_ref': False, 'colocate_all_models': True, 'actor_num_nodes': 1, 'actor_num_gpus_per_node': 2, 'critic_num_nodes': 1, 'critic_num_gpus_per_node': 2, 'colocate_critic_reward': False, 'vllm_num_engines': 2, 'vllm_tensor_parallel_size': 1, 'vllm_sync_backend': 'nccl', 'vllm_gpu_memory_utilization': 0.6, 'vllm_enable_sleep': True, 'deepspeed_enable_sleep': True, 'enable_prefix_caching': False, 'enforce_eager': False, 'eval_steps': 5, 'logging_steps': 1, 'save_steps': 1000, 'ckpt_path': '/data/MARTI-Search/outputs/reinforce-mad-3x2-unshared//0810/Qwen2.5-3B/ckpt', 'max_ckpt_num': 100, 'max_ckpt_mem': 100000000, 'load_checkpoint': False, 'local_rank': -1, 'zero_stage': 3, 'gradient_checkpointing': True, 'bf16': True, 'enable_ema': False, 'zpg': 1, 'adam_offload': True, 'actor_init_on_gpu': False, 'flash_attn': False, 'grad_accum_dtype': None, 'disable_trace_cache': False, 'gradient_checkpointing_use_reentrant': False, 'disable_fast_tokenizer': False, 'load_in_4bit': False, 'lora_rank': 0, 'lora_alpha': 16, 'target_modules': 'all-linear', 'lora_dropout': 0.0, 'save_path': '/data/MARTI-Search/outputs/reinforce-mad-3x2-unshared/0810/Qwen2.5-3B/model', 'num_episodes': 5, 'rollout_batch_size': 128, 'micro_rollout_batch_size': 8, 'max_epochs': 1, 'max_len': None, 'prompt_max_len': 12288, 'generate_max_len': 4096, 'truncate_prompt': False, 'max_samples': 400000, 'max_norm': 1.0, 'l2': 0.0, 'ptx_coef': 0.05, 'eps_clip': 0.2, 'value_clip': 0.2, 'lambd': 1.0, 'gamma': 1.0, 'micro_train_batch_size': 4, 'train_batch_size': 128, 'normalize_reward': True, 'top_p': 1.0, 'temperature': 1.0, 'eval_temperature': 0.0, 'seed': 42, 'freezing_actor_steps': -1, 'n_samples_per_prompt': 8, 'save_value_network': False, 'use_kl_loss': True, 'actor_learning_rate': 1e-06, 'critic_learning_rate': 9e-06, 'lr_warmup_ratio': 0.03, 'lr_warmup_steps': None, 'kl_target': None, 'init_kl_coef': 0.0, 'use_kl_estimator_k3': False, 'aux_loss_coef': 0.0, 'adam_betas': [0.9, 0.95], 'reward_clip_range': [-10, 10], 'advantage_estimator': 'reinforce', 'no_advantage_std_norm': False, 'training_mode': 'rl', 'eos_token': None}generator_3

 {'role': 'generator', 'pg_strategy': 'SPREAD', 'is_reasoning_model': False, 'enable_thinking': False, 'is_tuning': True, 'pretrain': '/data/Qwen2.5-3B', 'reward_pretrain': None, 'remote_rm_url': None, 'critic_pretrain': None, 'value_head_prefix': 'score', 'ref_reward_offload': False, 'ref_num_nodes': 1, 'ref_num_gpus_per_node': 2, 'reward_num_nodes': 1, 'reward_num_gpus_per_node': 8, 'colocate_actor_ref': False, 'colocate_all_models': True, 'actor_num_nodes': 1, 'actor_num_gpus_per_node': 2, 'critic_num_nodes': 1, 'critic_num_gpus_per_node': 2, 'colocate_critic_reward': False, 'vllm_num_engines': 2, 'vllm_tensor_parallel_size': 1, 'vllm_sync_backend': 'nccl', 'vllm_gpu_memory_utilization': 0.6, 'vllm_enable_sleep': True, 'deepspeed_enable_sleep': True, 'enable_prefix_caching': False, 'enforce_eager': False, 'eval_steps': 5, 'logging_steps': 1, 'save_steps': 1000, 'ckpt_path': '/data/MARTI-Search/outputs/reinforce-mad-3x2-unshared//0810/Qwen2.5-3B/ckpt', 'max_ckpt_num': 100, 'max_ckpt_mem': 100000000, 'load_checkpoint': False, 'local_rank': -1, 'zero_stage': 3, 'gradient_checkpointing': True, 'bf16': True, 'enable_ema': False, 'zpg': 1, 'adam_offload': True, 'actor_init_on_gpu': False, 'flash_attn': False, 'grad_accum_dtype': None, 'disable_trace_cache': False, 'gradient_checkpointing_use_reentrant': False, 'disable_fast_tokenizer': False, 'load_in_4bit': False, 'lora_rank': 0, 'lora_alpha': 16, 'target_modules': 'all-linear', 'lora_dropout': 0.0, 'save_path': '/data/MARTI-Search/outputs/reinforce-mad-3x2-unshared/0810/Qwen2.5-3B/model', 'num_episodes': 5, 'rollout_batch_size': 128, 'micro_rollout_batch_size': 8, 'max_epochs': 1, 'max_len': None, 'prompt_max_len': 12288, 'generate_max_len': 4096, 'truncate_prompt': False, 'max_samples': 400000, 'max_norm': 1.0, 'l2': 0.0, 'ptx_coef': 0.05, 'eps_clip': 0.2, 'value_clip': 0.2, 'lambd': 1.0, 'gamma': 1.0, 'micro_train_batch_size': 4, 'train_batch_size': 128, 'normalize_reward': True, 'top_p': 1.0, 'temperature': 1.0, 'eval_temperature': 0.0, 'seed': 42, 'freezing_actor_steps': -1, 'n_samples_per_prompt': 8, 'save_value_network': False, 'use_kl_loss': True, 'actor_learning_rate': 1e-06, 'critic_learning_rate': 9e-06, 'lr_warmup_ratio': 0.03, 'lr_warmup_steps': None, 'kl_target': None, 'init_kl_coef': 0.0, 'use_kl_estimator_k3': False, 'aux_loss_coef': 0.0, 'adam_betas': [0.9, 0.95], 'reward_clip_range': [-10, 10], 'advantage_estimator': 'reinforce', 'no_advantage_std_norm': False, 'training_mode': 'rl', 'eos_token': None}
2025-08-10 14:47:13,892	WARNING worker.py:1504 -- SIGTERM handler is not set because current thread is not the main thread.
2025-08-10 14:47:13,893	INFO worker.py:1514 -- Using address 172.16.1.156:6379 set in the environment variable RAY_ADDRESS
2025-08-10 14:47:13,894	INFO worker.py:1654 -- Connecting to existing Ray cluster at address: 172.16.1.156:6379...
2025-08-10 14:47:14,154	INFO worker.py:1832 -- Connected to Ray cluster. View the dashboard at [1m[32m172.16.1.156:8265 [39m[22m
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:47:27 [__init__.py:239] Automatically detected platform cuda.
[36m(pid=1115137)[0m [2025-08-10 14:47:28,763] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(pid=1115137)[0m INFO 08-10 14:47:30 [importing.py:53] Triton module has been replaced with a placeholder.
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:47:38 [config.py:717] This model supports multiple tasks: {'generate', 'score', 'reward', 'classify', 'embed'}. Defaulting to 'generate'.
[36m(pid=1115139)[0m INFO 08-10 14:47:31 [__init__.py:239] Automatically detected platform cuda.[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=1115139)[0m [2025-08-10 14:47:29,026] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 2x across cluster][0m
[36m(pid=1115139)[0m INFO 08-10 14:47:30 [importing.py:53] Triton module has been replaced with a placeholder.[32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:47:38 [config.py:717] This model supports multiple tasks: {'generate', 'embed', 'classify', 'reward', 'score'}. Defaulting to 'generate'.
[36m(LLMRayActor pid=1115135)[0m INFO 08-10 14:47:38 [config.py:717] This model supports multiple tasks: {'classify', 'embed', 'generate', 'score', 'reward'}. Defaulting to 'generate'.
[36m(LLMRayActor pid=1115132)[0m INFO 08-10 14:47:39 [config.py:717] This model supports multiple tasks: {'classify', 'generate', 'score', 'embed', 'reward'}. Defaulting to 'generate'.
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:47:39 [config.py:717] This model supports multiple tasks: {'classify', 'reward', 'generate', 'embed', 'score'}. Defaulting to 'generate'.
[36m(LLMRayActor pid=1115133)[0m INFO 08-10 14:47:39 [config.py:717] This model supports multiple tasks: {'reward', 'score', 'generate', 'embed', 'classify'}. Defaulting to 'generate'.
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:47:42 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.
[36m(LLMRayActor pid=1115135)[0m WARNING 08-10 14:47:43 [utils.py:2382] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/getting_started/troubleshooting.html#python-multiprocessing for more information. Reason: In a Ray actor and can only be spawned
[36m(pid=1116930)[0m [2025-08-10 14:47:43,682] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(pid=1116930)[0m INFO 08-10 14:47:45 [importing.py:53] Triton module has been replaced with a placeholder.
[36m(pid=1116930)[0m INFO 08-10 14:47:45 [__init__.py:239] Automatically detected platform cuda.
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:47:45,792] [INFO] [comm.py:669:init_distributed] cdb=None
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:47:45,792] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(LLMRayActor pid=1115132)[0m INFO 08-10 14:47:42 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m WARNING 08-10 14:47:43 [utils.py:2382] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/getting_started/troubleshooting.html#python-multiprocessing for more information. Reason: In a Ray actor and can only be spawned[32m [repeated 5x across cluster][0m
[36m(pid=1116981)[0m [2025-08-10 14:47:43,817] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:47:51 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/Qwen2.5-3B', speculative_config=None, tokenizer='/data/Qwen2.5-3B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=/data/Qwen2.5-3B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
[36m(pid=1116981)[0m INFO 08-10 14:47:46 [importing.py:53] Triton module has been replaced with a placeholder.[32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m INFO 08-10 14:47:48 [__init__.py:239] Automatically detected platform cuda.[32m [repeated 8x across cluster][0m
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:47:46,008] [INFO] [comm.py:669:init_distributed] cdb=None[32m [repeated 2x across cluster][0m
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:47:46,009] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl[32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:47:51 [worker_base.py:589] Injected <class 'marti.models.vllm.wrapper.WorkerWrap'> into <class 'vllm.v1.worker.gpu_worker.Worker'> for extended collective_rpc calls ['init_process_group', 'update_weight', 'update_weight_cuda_ipc']
[36m(LLMRayActor pid=1115131)[0m WARNING 08-10 14:47:51 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7dfb2600c9a0>
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:47:53 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:47:53 [cuda.py:221] Using Flash Attention backend on V1 engine.
[36m(LLMRayActor pid=1115131)[0m WARNING 08-10 14:47:53 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:47:53 [gpu_model_runner.py:1329] Starting to load model /data/Qwen2.5-3B...
[36m(LLMRayActor pid=1115131)[0m 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[36m(pid=1118203)[0m [2025-08-10 14:47:56,692] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:47:51 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='/data/Qwen2.5-3B', speculative_config=None, tokenizer='/data/Qwen2.5-3B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=83, served_model_name=/data/Qwen2.5-3B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:47:51 [worker_base.py:589] Injected <class 'marti.models.vllm.wrapper.WorkerWrap'> into <class 'vllm.v1.worker.gpu_worker.Worker'> for extended collective_rpc calls ['init_process_group', 'update_weight', 'update_weight_cuda_ipc'][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m WARNING 08-10 14:47:51 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fcd834f0bb0>[32m [repeated 5x across cluster][0m
[36m(pid=1118272)[0m [2025-08-10 14:47:56,694] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(LLMRayActor pid=1115131)[0m 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  4.18it/s]
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:47:57 [loader.py:458] Loading weights took 0.81 seconds
[36m(LLMRayActor pid=1115131)[0m 
[36m(LLMRayActor pid=1115135)[0m 
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:47:57 [gpu_model_runner.py:1347] Model loading took 5.7916 GiB and 4.316668 seconds
[36m(LLMRayActor pid=1115132)[0m 
[36m(LLMRayActor pid=1115136)[0m 
[36m(LLMRayActor pid=1115133)[0m 
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:47:57 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:47:57 [cuda.py:221] Using Flash Attention backend on V1 engine.[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m WARNING 08-10 14:47:57 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:47:57 [gpu_model_runner.py:1329] Starting to load model /data/Qwen2.5-3B...[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
[36m(ReferenceModelRayActor pid=1118203)[0m [2025-08-10 14:47:58,946] [INFO] [comm.py:669:init_distributed] cdb=None
[36m(ReferenceModelRayActor pid=1116919)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:47:59,052] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 2
[36m(ReferenceModelRayActor pid=1116958)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
[36m(LLMRayActor pid=1115134)[0m 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s][32m [repeated 5x across cluster][0m
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:01,765] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 435, num_elems = 3.40B
[36m(pid=1118337)[0m [2025-08-10 14:47:56,700] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[36m(ReferenceModelRayActor pid=1116958)[0m 
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.93it/s]
[36m(LLMRayActor pid=1115134)[0m 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  3.23it/s][32m [repeated 17x across cluster][0m
[36m(ReferenceModelRayActor pid=1118203)[0m 
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.62it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.49it/s]
[36m(ReferenceModelRayActor pid=1116958)[0m Actor(
[36m(ReferenceModelRayActor pid=1116958)[0m   (model): Qwen2ForCausalLM(
[36m(ReferenceModelRayActor pid=1116958)[0m     (model): Qwen2Model(
[36m(ReferenceModelRayActor pid=1116958)[0m       (embed_tokens): Embedding(151936, 2048)
[36m(ReferenceModelRayActor pid=1116958)[0m       (layers): ModuleList(
[36m(ReferenceModelRayActor pid=1116958)[0m         (0-35): 36 x Qwen2DecoderLayer(
[36m(ReferenceModelRayActor pid=1116958)[0m           (self_attn): Qwen2Attention(
[36m(ReferenceModelRayActor pid=1116958)[0m             (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
[36m(ReferenceModelRayActor pid=1116958)[0m             (k_proj): Linear(in_features=2048, out_features=256, bias=True)
[36m(ReferenceModelRayActor pid=1116958)[0m             (v_proj): Linear(in_features=2048, out_features=256, bias=True)
[36m(ReferenceModelRayActor pid=1116958)[0m             (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
[36m(ReferenceModelRayActor pid=1116958)[0m           )
[36m(ReferenceModelRayActor pid=1116958)[0m           (mlp): Qwen2MLP(
[36m(ReferenceModelRayActor pid=1116958)[0m             (gate_proj): Linear(in_features=2048, out_features=11008, bias=False)
[36m(ReferenceModelRayActor pid=1116958)[0m             (up_proj): Linear(in_features=2048, out_features=11008, bias=False)
[36m(ReferenceModelRayActor pid=1116958)[0m             (down_proj): Linear(in_features=11008, out_features=2048, bias=False)
[36m(ReferenceModelRayActor pid=1116958)[0m             (act_fn): SiLU()
[36m(ReferenceModelRayActor pid=1116958)[0m           )
[36m(ReferenceModelRayActor pid=1116958)[0m           (input_layernorm): Qwen2RMSNorm((0,), eps=1e-06)
[36m(ReferenceModelRayActor pid=1116958)[0m           (post_attention_layernorm): Qwen2RMSNorm((0,), eps=1e-06)
[36m(ReferenceModelRayActor pid=1116958)[0m         )
[36m(ReferenceModelRayActor pid=1116958)[0m       )
[36m(ReferenceModelRayActor pid=1116958)[0m       (norm): Qwen2RMSNorm((0,), eps=1e-06)
[36m(ReferenceModelRayActor pid=1116958)[0m       (rotary_emb): Qwen2RotaryEmbedding()
[36m(ReferenceModelRayActor pid=1116958)[0m     )
[36m(ReferenceModelRayActor pid=1116958)[0m     (lm_head): Linear(in_features=2048, out_features=151936, bias=False)
[36m(ReferenceModelRayActor pid=1116958)[0m   )
[36m(ReferenceModelRayActor pid=1116958)[0m )
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:02,608] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.8, git-hash=unknown, git-branch=unknown
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:02,608] [INFO] [comm.py:694:init_distributed] Distributed backend already initialized
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:47:58 [loader.py:458] Loading weights took 0.62 seconds[32m [repeated 5x across cluster][0m
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:02,618] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:02,619] [INFO] [logging.py:107:log_dist] [Rank 0] Creating ZeRO Offload
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:02,893] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:02,894] [INFO] [utils.py:782:see_memory_usage] MA 2.91 GB         Max_MA 4.07 GB         CA 4.46 GB         Max_CA 4 GB 
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:02,894] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 85.55 GB, percent = 4.2%
[36m(ReferenceModelRayActor pid=1116958)[0m Parameter Offload: Total persistent parameters: 241664 in 181 params
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:47:58 [gpu_model_runner.py:1347] Model loading took 5.7916 GiB and 0.827608 seconds[32m [repeated 5x across cluster][0m
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,181] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,181] [INFO] [utils.py:782:see_memory_usage] MA 2.91 GB         Max_MA 2.91 GB         CA 4.46 GB         Max_CA 4 GB 
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,182] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 85.57 GB, percent = 4.2%
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,183] [INFO] [config.py:1003:print] DeepSpeedEngine configuration:
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,183] [INFO] [config.py:1007:print]   activation_checkpointing_config  {
[36m(ReferenceModelRayActor pid=1116958)[0m     "partition_activations": false, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "contiguous_memory_optimization": false, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "cpu_checkpointing": false, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "number_checkpoints": null, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "synchronize_checkpoint_boundary": false, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "profile": false
[36m(ReferenceModelRayActor pid=1116958)[0m }
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,183] [INFO] [config.py:1007:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,183] [INFO] [config.py:1007:print]   amp_enabled .................. False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,183] [INFO] [config.py:1007:print]   amp_params ................... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   autotuning_config ............ {
[36m(ReferenceModelRayActor pid=1116958)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "start_step": null, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "end_step": null, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "metric_path": null, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "arg_mappings": null, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "metric": "throughput", 
[36m(ReferenceModelRayActor pid=1116958)[0m     "model_info": null, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "results_dir": "autotuning_results", 
[36m(ReferenceModelRayActor pid=1116958)[0m     "exps_dir": "autotuning_exps", 
[36m(ReferenceModelRayActor pid=1116958)[0m     "overwrite": true, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "fast": true, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "start_profile_step": 3, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "end_profile_step": 5, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "tuner_type": "gridsearch", 
[36m(ReferenceModelRayActor pid=1116958)[0m     "tuner_early_stopping": 5, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "tuner_num_trials": 50, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "model_info_path": null, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "mp_size": 1, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "max_train_batch_size": null, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "min_train_batch_size": 1, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "num_tuning_micro_batch_sizes": 3
[36m(ReferenceModelRayActor pid=1116958)[0m }
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   bfloat16_enabled ............. True
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   bfloat16_immediate_grad_update  True
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   checkpoint_parallel_write_pipeline  False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   checkpoint_tag_validation_enabled  True
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   checkpoint_tag_validation_fail  False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x72e528315180>
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   communication_data_type ...... None
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   curriculum_enabled_legacy .... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   curriculum_params_legacy ..... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   data_efficiency_enabled ...... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   dataloader_drop_last ......... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   disable_allgather ............ False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   dump_state ................... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   dynamic_loss_scale_args ...... None
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   eigenvalue_enabled ........... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   eigenvalue_gas_boundary_resolution  1
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   eigenvalue_layer_num ......... 0
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   eigenvalue_max_iter .......... 100
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   eigenvalue_stability ......... 1e-06
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   eigenvalue_tol ............... 0.01
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   eigenvalue_verbose ........... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   elasticity_enabled ........... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   flops_profiler_config ........ {
[36m(ReferenceModelRayActor pid=1116958)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "recompute_fwd_factor": 0.0, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "profile_step": 1, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "module_depth": -1, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "top_modules": 1, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "detailed": true, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "output_file": null
[36m(ReferenceModelRayActor pid=1116958)[0m }
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   fp16_auto_cast ............... None
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   fp16_enabled ................. False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   fp16_master_weights_and_gradients  False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   global_rank .................. 0
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   grad_accum_dtype ............. None
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,184] [INFO] [config.py:1007:print]   gradient_accumulation_steps .. 16
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   gradient_clipping ............ 1.0
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   gradient_predivide_factor .... 1.0
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   graph_harvesting ............. False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   initial_dynamic_scale ........ 1
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   load_universal_checkpoint .... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   loss_scale ................... 1.0
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   memory_breakdown ............. False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   mics_hierarchial_params_gather  False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   mics_shard_size .............. -1
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   nebula_config ................ {
[36m(ReferenceModelRayActor pid=1116958)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "persistent_storage_path": null, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "persistent_time_interval": 100, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "num_of_version_in_retention": 2, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "enable_nebula_load": true, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "load_path": null
[36m(ReferenceModelRayActor pid=1116958)[0m }
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   optimizer_legacy_fusion ...... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   optimizer_name ............... None
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   optimizer_params ............. None
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   pld_enabled .................. False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   pld_params ................... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   prescale_gradients ........... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   scheduler_name ............... None
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   scheduler_params ............. None
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   seq_parallel_communication_data_type  torch.float32
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   sparse_attention ............. None
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   sparse_gradients_enabled ..... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   steps_per_print .............. 100
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   timers_config ................ enabled=True synchronized=True
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   train_batch_size ............. 128
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   train_micro_batch_size_per_gpu  4
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   use_data_before_expert_parallel_  False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   use_node_local_storage ....... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,185] [INFO] [config.py:1007:print]   wall_clock_breakdown ......... False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,186] [INFO] [config.py:1007:print]   weight_quantization_config ... None
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,186] [INFO] [config.py:1007:print]   world_size ................... 2
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,186] [INFO] [config.py:1007:print]   zero_allow_untested_optimizer  False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,186] [INFO] [config.py:1007:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=True) offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,186] [INFO] [config.py:1007:print]   zero_enabled ................. True
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,186] [INFO] [config.py:1007:print]   zero_force_ds_cpu_optimizer .. True
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,186] [INFO] [config.py:1007:print]   zero_optimization_stage ...... 3
[36m(ReferenceModelRayActor pid=1116958)[0m [2025-08-10 14:48:03,186] [INFO] [config.py:993:print_user_config]   json = {
[36m(ReferenceModelRayActor pid=1116958)[0m     "steps_per_print": 100, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "zero_optimization": {
[36m(ReferenceModelRayActor pid=1116958)[0m         "stage": 3, 
[36m(ReferenceModelRayActor pid=1116958)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(ReferenceModelRayActor pid=1116958)[0m         "offload_param": {
[36m(ReferenceModelRayActor pid=1116958)[0m             "device": "none", 
[36m(ReferenceModelRayActor pid=1116958)[0m             "pin_memory": true
[36m(ReferenceModelRayActor pid=1116958)[0m         }
[36m(ReferenceModelRayActor pid=1116958)[0m     }, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "bf16": {
[36m(ReferenceModelRayActor pid=1116958)[0m         "enabled": true
[36m(ReferenceModelRayActor pid=1116958)[0m     }, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "gradient_clipping": 1.0, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "prescale_gradients": false, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "wall_clock_breakdown": false, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "train_micro_batch_size_per_gpu": 4, 
[36m(ReferenceModelRayActor pid=1116958)[0m     "train_batch_size": 128
[36m(ReferenceModelRayActor pid=1116958)[0m }
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:03,627] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(ActorModelRayActor pid=1115138)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.[32m [repeated 6x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:03,627] [INFO] [comm.py:669:init_distributed] cdb=None[32m [repeated 4x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:04,164] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 2[32m [repeated 8x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:48:05 [backends.py:420] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/9a3aa174cb/rank_0_0 for vLLM's torch.compile
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:48:05 [backends.py:430] Dynamo bytecode transform time: 7.84 s
[36m(ActorModelRayActor pid=1115138)[0m Using /home/ubuntu/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
[36m(ActorModelRayActor pid=1116965)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][32m [repeated 3x across cluster][0m
[36m(ActorModelRayActor pid=1116965)[0m 
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.05it/s][32m [repeated 3x across cluster][0m
[36m(ActorModelRayActor pid=1116965)[0m 
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.71it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.58it/s][32m [repeated 3x across cluster][0m
[36m(ActorModelRayActor pid=1116965)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorModelRayActor pid=1115138)[0m Installed CUDA version 12.8 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:05,305] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 435, num_elems = 3.40B
[36m(ActorModelRayActor pid=1116965)[0m [2025-08-10 14:48:04,143] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 2
[36m(ActorModelRayActor pid=1116965)[0m Creating extension directory /home/ubuntu/.cache/torch_extensions/py310_cu124/cpu_adam...
[36m(ActorModelRayActor pid=1116965)[0m Detected CUDA files, patching ldflags
[36m(ActorModelRayActor pid=1116965)[0m Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
[36m(ActorModelRayActor pid=1116965)[0m /home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[36m(ActorModelRayActor pid=1116965)[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
[36m(ActorModelRayActor pid=1116965)[0m   warnings.warn(
[36m(ActorModelRayActor pid=1116965)[0m Building extension module cpu_adam...
[36m(ActorModelRayActor pid=1116965)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(LLMRayActor pid=1115132)[0m INFO 08-10 14:48:11 [backends.py:136] Cache the graph of shape None for later use
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:48:06 [backends.py:420] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/9a3aa174cb/rank_0_0 for vLLM's torch.compile[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:48:06 [backends.py:430] Dynamo bytecode transform time: 7.84 s[32m [repeated 5x across cluster][0m
[36m(ActorModelRayActor pid=1116965)[0m Using /home/ubuntu/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
[36m(ReferenceModelRayActor pid=1116919)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:20,983] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 435, num_elems = 3.40B
[36m(ActorModelRayActor pid=1116965)[0m Installed CUDA version 12.8 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:48:11 [backends.py:136] Cache the graph of shape None for later use[32m [repeated 5x across cluster][0m
[36m(ReferenceModelRayActor pid=1118337)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
[36m(ReferenceModelRayActor pid=1116919)[0m 
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.89it/s]
[36m(ReferenceModelRayActor pid=1116919)[0m 
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.54it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.42it/s]
[36m(ReferenceModelRayActor pid=1116919)[0m Actor(
[36m(ReferenceModelRayActor pid=1116919)[0m   (model): Qwen2ForCausalLM(
[36m(ReferenceModelRayActor pid=1116919)[0m     (model): Qwen2Model(
[36m(ReferenceModelRayActor pid=1116919)[0m       (embed_tokens): Embedding(151936, 2048)
[36m(ReferenceModelRayActor pid=1116919)[0m       (layers): ModuleList(
[36m(ReferenceModelRayActor pid=1116919)[0m         (0-35): 36 x Qwen2DecoderLayer(
[36m(ReferenceModelRayActor pid=1116919)[0m           (self_attn): Qwen2Attention(
[36m(ReferenceModelRayActor pid=1116919)[0m             (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
[36m(ReferenceModelRayActor pid=1116919)[0m             (k_proj): Linear(in_features=2048, out_features=256, bias=True)
[36m(ReferenceModelRayActor pid=1116919)[0m             (v_proj): Linear(in_features=2048, out_features=256, bias=True)
[36m(ReferenceModelRayActor pid=1116919)[0m             (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
[36m(ReferenceModelRayActor pid=1116919)[0m           )
[36m(ReferenceModelRayActor pid=1116919)[0m           (mlp): Qwen2MLP(
[36m(ReferenceModelRayActor pid=1116919)[0m             (gate_proj): Linear(in_features=2048, out_features=11008, bias=False)
[36m(ReferenceModelRayActor pid=1116919)[0m             (up_proj): Linear(in_features=2048, out_features=11008, bias=False)
[36m(ReferenceModelRayActor pid=1116919)[0m             (down_proj): Linear(in_features=11008, out_features=2048, bias=False)
[36m(ReferenceModelRayActor pid=1116919)[0m             (act_fn): SiLU()
[36m(ReferenceModelRayActor pid=1116919)[0m           )
[36m(ReferenceModelRayActor pid=1116919)[0m           (input_layernorm): Qwen2RMSNorm((0,), eps=1e-06)
[36m(ReferenceModelRayActor pid=1116919)[0m           (post_attention_layernorm): Qwen2RMSNorm((0,), eps=1e-06)
[36m(ReferenceModelRayActor pid=1116919)[0m         )
[36m(ReferenceModelRayActor pid=1116919)[0m       )
[36m(ReferenceModelRayActor pid=1116919)[0m       (norm): Qwen2RMSNorm((0,), eps=1e-06)
[36m(ReferenceModelRayActor pid=1116919)[0m       (rotary_emb): Qwen2RotaryEmbedding()
[36m(ReferenceModelRayActor pid=1116919)[0m     )
[36m(ReferenceModelRayActor pid=1116919)[0m     (lm_head): Linear(in_features=2048, out_features=151936, bias=False)
[36m(ReferenceModelRayActor pid=1116919)[0m   )
[36m(ReferenceModelRayActor pid=1116919)[0m )
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:21,841] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.8, git-hash=unknown, git-branch=unknown
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:21,841] [INFO] [comm.py:694:init_distributed] Distributed backend already initialized
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:21,841] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 2
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:21,853] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:21,854] [INFO] [logging.py:107:log_dist] [Rank 0] Creating ZeRO Offload
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,241] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,242] [INFO] [utils.py:782:see_memory_usage] MA 2.91 GB         Max_MA 4.07 GB         CA 4.46 GB         Max_CA 4 GB 
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,243] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 89.49 GB, percent = 4.4%
[36m(ReferenceModelRayActor pid=1116919)[0m Parameter Offload: Total persistent parameters: 241664 in 181 params
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,519] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,520] [INFO] [utils.py:782:see_memory_usage] MA 2.91 GB         Max_MA 2.91 GB         CA 4.46 GB         Max_CA 4 GB 
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,520] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 89.57 GB, percent = 4.4%
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,521] [INFO] [config.py:1003:print] DeepSpeedEngine configuration:
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   activation_checkpointing_config  {
[36m(ReferenceModelRayActor pid=1116919)[0m     "partition_activations": false, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "contiguous_memory_optimization": false, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "cpu_checkpointing": false, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "number_checkpoints": null, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "synchronize_checkpoint_boundary": false, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "profile": false
[36m(ReferenceModelRayActor pid=1116919)[0m }
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   amp_enabled .................. False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   amp_params ................... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   autotuning_config ............ {
[36m(ReferenceModelRayActor pid=1116919)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "start_step": null, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "end_step": null, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "metric_path": null, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "arg_mappings": null, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "metric": "throughput", 
[36m(ReferenceModelRayActor pid=1116919)[0m     "model_info": null, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "results_dir": "autotuning_results", 
[36m(ReferenceModelRayActor pid=1116919)[0m     "exps_dir": "autotuning_exps", 
[36m(ReferenceModelRayActor pid=1116919)[0m     "overwrite": true, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "fast": true, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "start_profile_step": 3, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "end_profile_step": 5, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "tuner_type": "gridsearch", 
[36m(ReferenceModelRayActor pid=1116919)[0m     "tuner_early_stopping": 5, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "tuner_num_trials": 50, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "model_info_path": null, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "mp_size": 1, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "max_train_batch_size": null, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "min_train_batch_size": 1, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "num_tuning_micro_batch_sizes": 3
[36m(ReferenceModelRayActor pid=1116919)[0m }
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   bfloat16_enabled ............. True
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   bfloat16_immediate_grad_update  True
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   checkpoint_parallel_write_pipeline  False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   checkpoint_tag_validation_enabled  True
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   checkpoint_tag_validation_fail  False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x71a9e81b19f0>
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   communication_data_type ...... None
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   curriculum_enabled_legacy .... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   curriculum_params_legacy ..... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   data_efficiency_enabled ...... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   dataloader_drop_last ......... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   disable_allgather ............ False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,522] [INFO] [config.py:1007:print]   dump_state ................... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   dynamic_loss_scale_args ...... None
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   eigenvalue_enabled ........... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   eigenvalue_gas_boundary_resolution  1
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   eigenvalue_layer_num ......... 0
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   eigenvalue_max_iter .......... 100
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   eigenvalue_stability ......... 1e-06
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   eigenvalue_tol ............... 0.01
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   eigenvalue_verbose ........... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   elasticity_enabled ........... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   flops_profiler_config ........ {
[36m(ReferenceModelRayActor pid=1116919)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "recompute_fwd_factor": 0.0, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "profile_step": 1, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "module_depth": -1, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "top_modules": 1, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "detailed": true, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "output_file": null
[36m(ReferenceModelRayActor pid=1116919)[0m }
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   fp16_auto_cast ............... None
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   fp16_enabled ................. False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   fp16_master_weights_and_gradients  False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   global_rank .................. 0
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   grad_accum_dtype ............. None
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   gradient_accumulation_steps .. 16
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   gradient_clipping ............ 1.0
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   gradient_predivide_factor .... 1.0
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   graph_harvesting ............. False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   initial_dynamic_scale ........ 1
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   load_universal_checkpoint .... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   loss_scale ................... 1.0
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   memory_breakdown ............. False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   mics_hierarchial_params_gather  False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   mics_shard_size .............. -1
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   nebula_config ................ {
[36m(ReferenceModelRayActor pid=1116919)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "persistent_storage_path": null, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "persistent_time_interval": 100, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "num_of_version_in_retention": 2, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "enable_nebula_load": true, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "load_path": null
[36m(ReferenceModelRayActor pid=1116919)[0m }
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   optimizer_legacy_fusion ...... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   optimizer_name ............... None
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   optimizer_params ............. None
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   pld_enabled .................. False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   pld_params ................... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,523] [INFO] [config.py:1007:print]   prescale_gradients ........... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   scheduler_name ............... None
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   scheduler_params ............. None
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   seq_parallel_communication_data_type  torch.float32
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   sparse_attention ............. None
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   sparse_gradients_enabled ..... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   steps_per_print .............. 100
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   timers_config ................ enabled=True synchronized=True
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   train_batch_size ............. 128
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   train_micro_batch_size_per_gpu  4
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   use_data_before_expert_parallel_  False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   use_node_local_storage ....... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   wall_clock_breakdown ......... False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   weight_quantization_config ... None
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   world_size ................... 2
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   zero_allow_untested_optimizer  False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=True) offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   zero_enabled ................. True
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   zero_force_ds_cpu_optimizer .. True
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:1007:print]   zero_optimization_stage ...... 3
[36m(ReferenceModelRayActor pid=1116919)[0m [2025-08-10 14:48:22,524] [INFO] [config.py:993:print_user_config]   json = {
[36m(ReferenceModelRayActor pid=1116919)[0m     "steps_per_print": 100, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "zero_optimization": {
[36m(ReferenceModelRayActor pid=1116919)[0m         "stage": 3, 
[36m(ReferenceModelRayActor pid=1116919)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(ReferenceModelRayActor pid=1116919)[0m         "offload_param": {
[36m(ReferenceModelRayActor pid=1116919)[0m             "device": "none", 
[36m(ReferenceModelRayActor pid=1116919)[0m             "pin_memory": true
[36m(ReferenceModelRayActor pid=1116919)[0m         }
[36m(ReferenceModelRayActor pid=1116919)[0m     }, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "bf16": {
[36m(ReferenceModelRayActor pid=1116919)[0m         "enabled": true
[36m(ReferenceModelRayActor pid=1116919)[0m     }, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "gradient_clipping": 1.0, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "prescale_gradients": false, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "wall_clock_breakdown": false, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "train_micro_batch_size_per_gpu": 4, 
[36m(ReferenceModelRayActor pid=1116919)[0m     "train_batch_size": 128
[36m(ReferenceModelRayActor pid=1116919)[0m }
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:22,899] [INFO] [comm.py:669:init_distributed] cdb=None
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:22,900] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(ActorModelRayActor pid=1116930)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorModelRayActor pid=1115137)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][32m [repeated 2x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.89it/s][32m [repeated 2x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.94it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.93it/s][32m [repeated 2x across cluster][0m
[36m(ActorModelRayActor pid=1116930)[0m Using /home/ubuntu/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
[36m(ActorModelRayActor pid=1115137)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorModelRayActor pid=1116930)[0m Installed CUDA version 12.8 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:25,926] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 435, num_elems = 3.40B
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:23,629] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 2[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActor pid=1116930)[0m [2025-08-10 14:48:23,435] [INFO] [comm.py:669:init_distributed] cdb=None
[36m(ActorModelRayActor pid=1116965)[0m [1/3] c++ -MMD -MF cpu_adam_impl.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/home/ubuntu/.local/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -isystem /home/ubuntu/.local/lib/python3.10/site-packages/torch/include -isystem /home/ubuntu/.local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/.local/lib/python3.10/site-packages/torch/include/TH -isystem /home/ubuntu/.local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-12.8/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda-12.8/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /home/ubuntu/.local/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -o cpu_adam_impl.o 
[36m(ActorModelRayActor pid=1116965)[0m [2/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/home/ubuntu/.local/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -isystem /home/ubuntu/.local/lib/python3.10/site-packages/torch/include -isystem /home/ubuntu/.local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/.local/lib/python3.10/site-packages/torch/include/TH -isystem /home/ubuntu/.local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-12.8/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/usr/local/cuda-12.8/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /home/ubuntu/.local/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o 
[36m(ActorModelRayActor pid=1115138)[0m Loading extension module cpu_adam...
[36m(ActorModelRayActor pid=1116930)[0m 
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.86it/s]
[36m(ActorModelRayActor pid=1116930)[0m 
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.94it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.93it/s]
[36m(ActorModelRayActor pid=1115137)[0m Using /home/ubuntu/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
[36m(ActorModelRayActor pid=1115138)[0m Time to load cpu_adam op: 28.834147453308105 seconds
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,219] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.8, git-hash=unknown, git-branch=unknown
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,220] [INFO] [comm.py:694:init_distributed] Distributed backend already initialized
[36m(ActorModelRayActor pid=1115137)[0m Installed CUDA version 12.8 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,220] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 2
[36m(ActorModelRayActor pid=1116930)[0m [2025-08-10 14:48:36,216] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 2
[36m(ActorModelRayActor pid=1116965)[0m [3/3] c++ cpu_adam.o cpu_adam_impl.o -shared -lcurand -L/usr/local/cuda-12.8/lib64 -L/home/ubuntu/.local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda-12.8/lib64 -lcudart -o cpu_adam.so
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,237] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,239] [INFO] [logging.py:107:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,239] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,263] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,263] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,263] [INFO] [logging.py:107:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,263] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,622] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,623] [INFO] [utils.py:782:see_memory_usage] MA 2.91 GB         Max_MA 4.36 GB         CA 4.46 GB         Max_CA 4 GB 
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,623] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 88.87 GB, percent = 4.4%
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,625] [INFO] [stage3.py:170:__init__] Reduce bucket size 500000000
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,625] [INFO] [stage3.py:171:__init__] Prefetch bucket size 50000000
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:36,908] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(ActorModelRayActor pid=1115138)[0m Parameter Offload: Total persistent parameters: 241664 in 181 params
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:37,260] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:37,559] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:40,733] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 3
[36m(LLMRayActor pid=1115135)[0m INFO 08-10 14:48:47 [backends.py:148] Compiling a graph for general shape takes 40.54 s
[36m(ActorModelRayActor pid=1116965)[0m Time to load cpu_adam op: 28.821746587753296 seconds[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,226] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.8, git-hash=unknown, git-branch=unknown
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,226] [INFO] [comm.py:694:init_distributed] Distributed backend already initialized
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,227] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 2[32m [repeated 2x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,253] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,255] [INFO] [logging.py:107:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,255] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,288] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,288] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,288] [INFO] [logging.py:107:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,288] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,792] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:41,081] [INFO] [utils.py:782:see_memory_usage] MA 2.87 GB         Max_MA 2.87 GB         CA 2.88 GB         Max_CA 3 GB [32m [repeated 11x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:41,081] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 91.9 GB, percent = 4.6%[32m [repeated 11x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,795] [INFO] [stage3.py:170:__init__] Reduce bucket size 500000000
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:36,795] [INFO] [stage3.py:171:__init__] Prefetch bucket size 50000000
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:37,121] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(ActorModelRayActor pid=1115137)[0m Parameter Offload: Total persistent parameters: 241664 in 181 params
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:37,664] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:41,080] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:40,812] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 3
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:47,477] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:47,746] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:58,773] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:58,775] [INFO] [stage3.py:534:_setup_for_real_optimizer] optimizer state initialized
[36m(LLMRayActor pid=1115132)[0m INFO 08-10 14:48:47 [backends.py:148] Compiling a graph for general shape takes 40.88 s[32m [repeated 5x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:58,774] [INFO] [utils.py:782:see_memory_usage] MA 2.87 GB         Max_MA 2.87 GB         CA 2.88 GB         Max_CA 3 GB [32m [repeated 5x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:48:58,774] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 158.06 GB, percent = 7.8%[32m [repeated 5x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:47,634] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:48:47,909] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:49:01 [monitor.py:33] torch.compile takes 48.57 s in total
[36m(LLMRayActor pid=1115135)[0m INFO 08-10 14:49:02 [kv_cache_utils.py:634] GPU KV cache size: 971,568 tokens
[36m(LLMRayActor pid=1115135)[0m INFO 08-10 14:49:02 [kv_cache_utils.py:637] Maximum concurrency for 16,384 tokens per request: 59.30x
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:02,289] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 435, num_elems = 3.40B
[36m(ReferenceModelRayActor pid=1116980)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
[36m(ActorModelRayActor pid=1116965)[0m Loading extension module cpu_adam...[32m [repeated 3x across cluster][0m
[36m(ReferenceModelRayActor pid=1116980)[0m 
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.45it/s]
[36m(ReferenceModelRayActor pid=1116980)[0m Actor(
[36m(ReferenceModelRayActor pid=1116980)[0m   (model): Qwen2ForCausalLM(
[36m(ReferenceModelRayActor pid=1116980)[0m     (model): Qwen2Model(
[36m(ReferenceModelRayActor pid=1116980)[0m       (embed_tokens): Embedding(151936, 2048)
[36m(ReferenceModelRayActor pid=1116980)[0m       (layers): ModuleList(
[36m(ReferenceModelRayActor pid=1116980)[0m         (0-35): 36 x Qwen2DecoderLayer(
[36m(ReferenceModelRayActor pid=1116980)[0m           (self_attn): Qwen2Attention(
[36m(ReferenceModelRayActor pid=1116980)[0m             (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
[36m(ReferenceModelRayActor pid=1116980)[0m             (k_proj): Linear(in_features=2048, out_features=256, bias=True)
[36m(ReferenceModelRayActor pid=1116980)[0m             (v_proj): Linear(in_features=2048, out_features=256, bias=True)
[36m(ReferenceModelRayActor pid=1116980)[0m             (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
[36m(ReferenceModelRayActor pid=1116980)[0m           )
[36m(ReferenceModelRayActor pid=1116980)[0m           (mlp): Qwen2MLP(
[36m(ReferenceModelRayActor pid=1116980)[0m             (gate_proj): Linear(in_features=2048, out_features=11008, bias=False)
[36m(ReferenceModelRayActor pid=1116980)[0m             (up_proj): Linear(in_features=2048, out_features=11008, bias=False)
[36m(ReferenceModelRayActor pid=1116980)[0m             (down_proj): Linear(in_features=11008, out_features=2048, bias=False)
[36m(ReferenceModelRayActor pid=1116980)[0m             (act_fn): SiLU()
[36m(ReferenceModelRayActor pid=1116980)[0m           )
[36m(ReferenceModelRayActor pid=1116980)[0m           (input_layernorm): Qwen2RMSNorm((0,), eps=1e-06)
[36m(ReferenceModelRayActor pid=1116980)[0m           (post_attention_layernorm): Qwen2RMSNorm((0,), eps=1e-06)
[36m(ReferenceModelRayActor pid=1116980)[0m         )
[36m(ReferenceModelRayActor pid=1116980)[0m       )
[36m(ReferenceModelRayActor pid=1116980)[0m       (norm): Qwen2RMSNorm((0,), eps=1e-06)
[36m(ReferenceModelRayActor pid=1116980)[0m       (rotary_emb): Qwen2RotaryEmbedding()
[36m(ReferenceModelRayActor pid=1116980)[0m     )
[36m(ReferenceModelRayActor pid=1116980)[0m     (lm_head): Linear(in_features=2048, out_features=151936, bias=False)
[36m(ReferenceModelRayActor pid=1116980)[0m   )
[36m(ReferenceModelRayActor pid=1116980)[0m )
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:02,975] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.8, git-hash=unknown, git-branch=unknown
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:02,975] [INFO] [comm.py:694:init_distributed] Distributed backend already initialized
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:02,975] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 2
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:02,985] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:02,987] [INFO] [logging.py:107:log_dist] [Rank 0] Creating ZeRO Offload
[36m(ReferenceModelRayActor pid=1116980)[0m 
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.19it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.05it/s]
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,314] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(ReferenceModelRayActor pid=1116980)[0m Parameter Offload: Total persistent parameters: 241664 in 181 params
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,603] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,605] [INFO] [config.py:1003:print] DeepSpeedEngine configuration:
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,605] [INFO] [config.py:1007:print]   activation_checkpointing_config  {
[36m(ReferenceModelRayActor pid=1116980)[0m     "partition_activations": false, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "contiguous_memory_optimization": false, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "cpu_checkpointing": false, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "number_checkpoints": null, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "synchronize_checkpoint_boundary": false, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "profile": false
[36m(ReferenceModelRayActor pid=1116980)[0m }
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,605] [INFO] [config.py:1007:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,605] [INFO] [config.py:1007:print]   amp_enabled .................. False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,605] [INFO] [config.py:1007:print]   amp_params ................... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,605] [INFO] [config.py:1007:print]   autotuning_config ............ {
[36m(ReferenceModelRayActor pid=1116980)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "start_step": null, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "end_step": null, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "metric_path": null, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "arg_mappings": null, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "metric": "throughput", 
[36m(ReferenceModelRayActor pid=1116980)[0m     "model_info": null, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "results_dir": "autotuning_results", 
[36m(ReferenceModelRayActor pid=1116980)[0m     "exps_dir": "autotuning_exps", 
[36m(ReferenceModelRayActor pid=1116980)[0m     "overwrite": true, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "fast": true, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "start_profile_step": 3, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "end_profile_step": 5, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "tuner_type": "gridsearch", 
[36m(ReferenceModelRayActor pid=1116980)[0m     "tuner_early_stopping": 5, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "tuner_num_trials": 50, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "model_info_path": null, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "mp_size": 1, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "max_train_batch_size": null, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "min_train_batch_size": 1, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "num_tuning_micro_batch_sizes": 3
[36m(ReferenceModelRayActor pid=1116980)[0m }
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,605] [INFO] [config.py:1007:print]   bfloat16_enabled ............. True
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,605] [INFO] [config.py:1007:print]   bfloat16_immediate_grad_update  True
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,605] [INFO] [config.py:1007:print]   checkpoint_parallel_write_pipeline  False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,605] [INFO] [config.py:1007:print]   checkpoint_tag_validation_enabled  True
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,605] [INFO] [config.py:1007:print]   checkpoint_tag_validation_fail  False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x6ff7b4188f40>
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   communication_data_type ...... None
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   curriculum_enabled_legacy .... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   curriculum_params_legacy ..... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   data_efficiency_enabled ...... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   dataloader_drop_last ......... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   disable_allgather ............ False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   dump_state ................... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   dynamic_loss_scale_args ...... None
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   eigenvalue_enabled ........... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   eigenvalue_gas_boundary_resolution  1
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   eigenvalue_layer_num ......... 0
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   eigenvalue_max_iter .......... 100
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   eigenvalue_stability ......... 1e-06
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   eigenvalue_tol ............... 0.01
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   eigenvalue_verbose ........... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   elasticity_enabled ........... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   flops_profiler_config ........ {
[36m(ReferenceModelRayActor pid=1116980)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "recompute_fwd_factor": 0.0, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "profile_step": 1, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "module_depth": -1, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "top_modules": 1, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "detailed": true, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "output_file": null
[36m(ReferenceModelRayActor pid=1116980)[0m }
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   fp16_auto_cast ............... None
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   fp16_enabled ................. False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   fp16_master_weights_and_gradients  False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   global_rank .................. 0
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   grad_accum_dtype ............. None
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   gradient_accumulation_steps .. 16
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   gradient_clipping ............ 1.0
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   gradient_predivide_factor .... 1.0
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   graph_harvesting ............. False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   initial_dynamic_scale ........ 1
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   load_universal_checkpoint .... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   loss_scale ................... 1.0
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,606] [INFO] [config.py:1007:print]   memory_breakdown ............. False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   mics_hierarchial_params_gather  False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   mics_shard_size .............. -1
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   nebula_config ................ {
[36m(ReferenceModelRayActor pid=1116980)[0m     "enabled": false, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "persistent_storage_path": null, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "persistent_time_interval": 100, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "num_of_version_in_retention": 2, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "enable_nebula_load": true, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "load_path": null
[36m(ReferenceModelRayActor pid=1116980)[0m }
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   optimizer_legacy_fusion ...... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   optimizer_name ............... None
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   optimizer_params ............. None
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   pld_enabled .................. False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   pld_params ................... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   prescale_gradients ........... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   scheduler_name ............... None
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   scheduler_params ............. None
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   seq_parallel_communication_data_type  torch.float32
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   sparse_attention ............. None
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   sparse_gradients_enabled ..... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   steps_per_print .............. 100
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   timers_config ................ enabled=True synchronized=True
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   train_batch_size ............. 128
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   train_micro_batch_size_per_gpu  4
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   use_data_before_expert_parallel_  False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   use_node_local_storage ....... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   wall_clock_breakdown ......... False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   weight_quantization_config ... None
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   world_size ................... 2
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   zero_allow_untested_optimizer  False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=True) offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   zero_enabled ................. True
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   zero_force_ds_cpu_optimizer .. True
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,607] [INFO] [config.py:1007:print]   zero_optimization_stage ...... 3
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,608] [INFO] [config.py:993:print_user_config]   json = {
[36m(ReferenceModelRayActor pid=1116980)[0m     "steps_per_print": 100, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "zero_optimization": {
[36m(ReferenceModelRayActor pid=1116980)[0m         "stage": 3, 
[36m(ReferenceModelRayActor pid=1116980)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(ReferenceModelRayActor pid=1116980)[0m         "offload_param": {
[36m(ReferenceModelRayActor pid=1116980)[0m             "device": "none", 
[36m(ReferenceModelRayActor pid=1116980)[0m             "pin_memory": true
[36m(ReferenceModelRayActor pid=1116980)[0m         }
[36m(ReferenceModelRayActor pid=1116980)[0m     }, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "bf16": {
[36m(ReferenceModelRayActor pid=1116980)[0m         "enabled": true
[36m(ReferenceModelRayActor pid=1116980)[0m     }, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "gradient_clipping": 1.0, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "prescale_gradients": false, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "wall_clock_breakdown": false, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "train_micro_batch_size_per_gpu": 4, 
[36m(ReferenceModelRayActor pid=1116980)[0m     "train_batch_size": 128
[36m(ReferenceModelRayActor pid=1116980)[0m }
[36m(ActorModelRayActor pid=1116981)[0m [2025-08-10 14:49:03,973] [INFO] [comm.py:669:init_distributed] cdb=None
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:01,158] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:01,160] [INFO] [stage3.py:534:_setup_for_real_optimizer] optimizer state initialized
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,603] [INFO] [utils.py:782:see_memory_usage] MA 2.91 GB         Max_MA 2.91 GB         CA 4.46 GB         Max_CA 4 GB [32m [repeated 3x across cluster][0m
[36m(ReferenceModelRayActor pid=1116980)[0m [2025-08-10 14:49:03,603] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 179.32 GB, percent = 8.9%[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:04,050] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[36m(ActorModelRayActor pid=1115139)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:49:02 [monitor.py:33] torch.compile takes 47.94 s in total[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:49:03 [kv_cache_utils.py:634] GPU KV cache size: 722,304 tokens[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:49:03 [kv_cache_utils.py:637] Maximum concurrency for 16,384 tokens per request: 44.09x[32m [repeated 5x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:08,957] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 435, num_elems = 3.40B
[36m(ActorModelRayActor pid=1116981)[0m [2025-08-10 14:49:04,681] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 2[32m [repeated 3x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][32m [repeated 2x across cluster][0m
[36m(ReferenceModelRayActor pid=1118272)[0m 
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.47it/s]
[36m(ReferenceModelRayActor pid=1118272)[0m 
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.29it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.13it/s]
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,541] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,542] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,543] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,543] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x790070724130>
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,543] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[[0.9, 0.95], [0.9, 0.95]]
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,544] [INFO] [config.py:1003:print] DeepSpeedEngine configuration:
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,544] [INFO] [config.py:1007:print]   activation_checkpointing_config  {
[36m(ActorModelRayActor pid=1115137)[0m     "partition_activations": false, 
[36m(ActorModelRayActor pid=1115137)[0m     "contiguous_memory_optimization": false, 
[36m(ActorModelRayActor pid=1115137)[0m     "cpu_checkpointing": false, 
[36m(ActorModelRayActor pid=1115137)[0m     "number_checkpoints": null, 
[36m(ActorModelRayActor pid=1115137)[0m     "synchronize_checkpoint_boundary": false, 
[36m(ActorModelRayActor pid=1115137)[0m     "profile": false
[36m(ActorModelRayActor pid=1115137)[0m }
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,544] [INFO] [config.py:1007:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   amp_enabled .................. False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   amp_params ................... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   autotuning_config ............ {
[36m(ActorModelRayActor pid=1115137)[0m     "enabled": false, 
[36m(ActorModelRayActor pid=1115137)[0m     "start_step": null, 
[36m(ActorModelRayActor pid=1115137)[0m     "end_step": null, 
[36m(ActorModelRayActor pid=1115137)[0m     "metric_path": null, 
[36m(ActorModelRayActor pid=1115137)[0m     "arg_mappings": null, 
[36m(ActorModelRayActor pid=1115137)[0m     "metric": "throughput", 
[36m(ActorModelRayActor pid=1115137)[0m     "model_info": null, 
[36m(ActorModelRayActor pid=1115137)[0m     "results_dir": "autotuning_results", 
[36m(ActorModelRayActor pid=1115137)[0m     "exps_dir": "autotuning_exps", 
[36m(ActorModelRayActor pid=1115137)[0m     "overwrite": true, 
[36m(ActorModelRayActor pid=1115137)[0m     "fast": true, 
[36m(ActorModelRayActor pid=1115137)[0m     "start_profile_step": 3, 
[36m(ActorModelRayActor pid=1115137)[0m     "end_profile_step": 5, 
[36m(ActorModelRayActor pid=1115137)[0m     "tuner_type": "gridsearch", 
[36m(ActorModelRayActor pid=1115137)[0m     "tuner_early_stopping": 5, 
[36m(ActorModelRayActor pid=1115137)[0m     "tuner_num_trials": 50, 
[36m(ActorModelRayActor pid=1115137)[0m     "model_info_path": null, 
[36m(ActorModelRayActor pid=1115137)[0m     "mp_size": 1, 
[36m(ActorModelRayActor pid=1115137)[0m     "max_train_batch_size": null, 
[36m(ActorModelRayActor pid=1115137)[0m     "min_train_batch_size": 1, 
[36m(ActorModelRayActor pid=1115137)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(ActorModelRayActor pid=1115137)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(ActorModelRayActor pid=1115137)[0m     "num_tuning_micro_batch_sizes": 3
[36m(ActorModelRayActor pid=1115137)[0m }
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   bfloat16_enabled ............. True
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   bfloat16_immediate_grad_update  True
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   checkpoint_parallel_write_pipeline  False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   checkpoint_tag_validation_enabled  True
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   checkpoint_tag_validation_fail  False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x79009001f8e0>
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   communication_data_type ...... None
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   curriculum_enabled_legacy .... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   curriculum_params_legacy ..... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   data_efficiency_enabled ...... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   dataloader_drop_last ......... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   disable_allgather ............ False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   dump_state ................... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   dynamic_loss_scale_args ...... None
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   eigenvalue_enabled ........... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,545] [INFO] [config.py:1007:print]   eigenvalue_gas_boundary_resolution  1
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   eigenvalue_layer_num ......... 0
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   eigenvalue_max_iter .......... 100
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   eigenvalue_stability ......... 1e-06
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   eigenvalue_tol ............... 0.01
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   eigenvalue_verbose ........... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   elasticity_enabled ........... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   flops_profiler_config ........ {
[36m(ActorModelRayActor pid=1115137)[0m     "enabled": false, 
[36m(ActorModelRayActor pid=1115137)[0m     "recompute_fwd_factor": 0.0, 
[36m(ActorModelRayActor pid=1115137)[0m     "profile_step": 1, 
[36m(ActorModelRayActor pid=1115137)[0m     "module_depth": -1, 
[36m(ActorModelRayActor pid=1115137)[0m     "top_modules": 1, 
[36m(ActorModelRayActor pid=1115137)[0m     "detailed": true, 
[36m(ActorModelRayActor pid=1115137)[0m     "output_file": null
[36m(ActorModelRayActor pid=1115137)[0m }
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   fp16_auto_cast ............... None
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   fp16_enabled ................. False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   fp16_master_weights_and_gradients  False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   global_rank .................. 0
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   grad_accum_dtype ............. fp32
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   gradient_accumulation_steps .. 16
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   gradient_clipping ............ 1.0
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   gradient_predivide_factor .... 1.0
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   graph_harvesting ............. False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   initial_dynamic_scale ........ 1
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   load_universal_checkpoint .... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   loss_scale ................... 1.0
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   memory_breakdown ............. False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   mics_hierarchial_params_gather  False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   mics_shard_size .............. -1
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   nebula_config ................ {
[36m(ActorModelRayActor pid=1115137)[0m     "enabled": false, 
[36m(ActorModelRayActor pid=1115137)[0m     "persistent_storage_path": null, 
[36m(ActorModelRayActor pid=1115137)[0m     "persistent_time_interval": 100, 
[36m(ActorModelRayActor pid=1115137)[0m     "num_of_version_in_retention": 2, 
[36m(ActorModelRayActor pid=1115137)[0m     "enable_nebula_load": true, 
[36m(ActorModelRayActor pid=1115137)[0m     "load_path": null
[36m(ActorModelRayActor pid=1115137)[0m }
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   optimizer_legacy_fusion ...... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   optimizer_name ............... None
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   optimizer_params ............. None
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   pld_enabled .................. False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   pld_params ................... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   prescale_gradients ........... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   scheduler_name ............... None
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,546] [INFO] [config.py:1007:print]   scheduler_params ............. None
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   seq_parallel_communication_data_type  torch.float32
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   sparse_attention ............. None
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   sparse_gradients_enabled ..... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   steps_per_print .............. 100
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   timers_config ................ enabled=True synchronized=True
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   train_batch_size ............. 128
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   train_micro_batch_size_per_gpu  4
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   use_data_before_expert_parallel_  False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   use_node_local_storage ....... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   wall_clock_breakdown ......... False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   weight_quantization_config ... None
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   world_size ................... 2
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   zero_allow_untested_optimizer  False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   zero_enabled ................. True
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   zero_force_ds_cpu_optimizer .. True
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:1007:print]   zero_optimization_stage ...... 3
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,547] [INFO] [config.py:993:print_user_config]   json = {
[36m(ActorModelRayActor pid=1115137)[0m     "steps_per_print": 100, 
[36m(ActorModelRayActor pid=1115137)[0m     "zero_optimization": {
[36m(ActorModelRayActor pid=1115137)[0m         "stage": 3, 
[36m(ActorModelRayActor pid=1115137)[0m         "offload_param": {
[36m(ActorModelRayActor pid=1115137)[0m             "device": "none"
[36m(ActorModelRayActor pid=1115137)[0m         }, 
[36m(ActorModelRayActor pid=1115137)[0m         "offload_optimizer": {
[36m(ActorModelRayActor pid=1115137)[0m             "device": "cpu", 
[36m(ActorModelRayActor pid=1115137)[0m             "pin_memory": true
[36m(ActorModelRayActor pid=1115137)[0m         }, 
[36m(ActorModelRayActor pid=1115137)[0m         "sub_group_size": "auto", 
[36m(ActorModelRayActor pid=1115137)[0m         "stage3_max_live_parameters": "auto", 
[36m(ActorModelRayActor pid=1115137)[0m         "stage3_max_reuse_distance": "auto", 
[36m(ActorModelRayActor pid=1115137)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(ActorModelRayActor pid=1115137)[0m         "stage3_prefetch_bucket_size": "auto", 
[36m(ActorModelRayActor pid=1115137)[0m         "reduce_bucket_size": "auto", 
[36m(ActorModelRayActor pid=1115137)[0m         "zero_hpz_partition_size": 1, 
[36m(ActorModelRayActor pid=1115137)[0m         "zero_quantized_weights": false, 
[36m(ActorModelRayActor pid=1115137)[0m         "zero_quantized_gradients": false
[36m(ActorModelRayActor pid=1115137)[0m     }, 
[36m(ActorModelRayActor pid=1115137)[0m     "bf16": {
[36m(ActorModelRayActor pid=1115137)[0m         "enabled": true
[36m(ActorModelRayActor pid=1115137)[0m     }, 
[36m(ActorModelRayActor pid=1115137)[0m     "gradient_clipping": 1.0, 
[36m(ActorModelRayActor pid=1115137)[0m     "prescale_gradients": false, 
[36m(ActorModelRayActor pid=1115137)[0m     "wall_clock_breakdown": false, 
[36m(ActorModelRayActor pid=1115137)[0m     "data_types": {
[36m(ActorModelRayActor pid=1115137)[0m         "grad_accum_dtype": "fp32"
[36m(ActorModelRayActor pid=1115137)[0m     }, 
[36m(ActorModelRayActor pid=1115137)[0m     "train_micro_batch_size_per_gpu": 4, 
[36m(ActorModelRayActor pid=1115137)[0m     "train_batch_size": 128
[36m(ActorModelRayActor pid=1115137)[0m }
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:04,050] [INFO] [comm.py:669:init_distributed] cdb=None
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,542] [INFO] [utils.py:782:see_memory_usage] MA 3.81 GB         Max_MA 4.97 GB         CA 4.97 GB         Max_CA 5 GB 
[36m(ActorModelRayActor pid=1115137)[0m [2025-08-10 14:49:09,542] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 195.6 GB, percent = 9.7%
[36m(ActorModelRayActor pid=1116981)[0m 
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.80it/s]
[36m(ActorModelRayActor pid=1115139)[0m 
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.22it/s]
[36m(ActorModelRayActor pid=1116981)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,351] [INFO] [utils.py:782:see_memory_usage] MA 3.81 GB         Max_MA 4.97 GB         CA 4.97 GB         Max_CA 5 GB 
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,351] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 182.74 GB, percent = 9.1%
[36m(ActorModelRayActor pid=1115139)[0m Using /home/ubuntu/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
[36m(ActorModelRayActor pid=1115139)[0m Detected CUDA files, patching ldflags
[36m(ActorModelRayActor pid=1115139)[0m Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
[36m(ActorModelRayActor pid=1115139)[0m /home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[36m(ActorModelRayActor pid=1115139)[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
[36m(ActorModelRayActor pid=1115139)[0m   warnings.warn(
[36m(ActorModelRayActor pid=1115139)[0m Building extension module cpu_adam...
[36m(ActorModelRayActor pid=1115139)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(ActorModelRayActor pid=1115139)[0m Loading extension module cpu_adam...
[36m(ActorModelRayActor pid=1115139)[0m Installed CUDA version 12.8 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
[36m(ActorModelRayActor pid=1115139)[0m ninja: no work to do.
[36m(ActorModelRayActor pid=1115139)[0m Time to load cpu_adam op: 2.5269312858581543 seconds
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:13,660] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.8, git-hash=unknown, git-branch=unknown
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:13,660] [INFO] [comm.py:694:init_distributed] Distributed backend already initialized
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:13,680] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:13,682] [INFO] [logging.py:107:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:13,682] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:13,716] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:13,716] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:13,716] [INFO] [logging.py:107:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:13,716] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:14,078] [INFO] [utils.py:781:see_memory_usage] Stage 3 initialize beginning
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:14,081] [INFO] [stage3.py:170:__init__] Reduce bucket size 500000000
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:14,081] [INFO] [stage3.py:171:__init__] Prefetch bucket size 50000000
[36m(ActorModelRayActor pid=1116981)[0m [2025-08-10 14:49:13,687] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 2[32m [repeated 2x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:14,342] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[36m(ActorModelRayActor pid=1115139)[0m Parameter Offload: Total persistent parameters: 241664 in 181 params
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:14,680] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,350] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,352] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,352] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,352] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7ac6f02ed870>
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,352] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[[0.9, 0.95], [0.9, 0.95]]
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,353] [INFO] [config.py:1003:print] DeepSpeedEngine configuration:
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,354] [INFO] [config.py:1007:print]   activation_checkpointing_config  {
[36m(ActorModelRayActor pid=1115138)[0m     "partition_activations": false, 
[36m(ActorModelRayActor pid=1115138)[0m     "contiguous_memory_optimization": false, 
[36m(ActorModelRayActor pid=1115138)[0m     "cpu_checkpointing": false, 
[36m(ActorModelRayActor pid=1115138)[0m     "number_checkpoints": null, 
[36m(ActorModelRayActor pid=1115138)[0m     "synchronize_checkpoint_boundary": false, 
[36m(ActorModelRayActor pid=1115138)[0m     "profile": false
[36m(ActorModelRayActor pid=1115138)[0m }[32m [repeated 5x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,354] [INFO] [config.py:1007:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,354] [INFO] [config.py:1007:print]   amp_enabled .................. False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,354] [INFO] [config.py:1007:print]   amp_params ................... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   autotuning_config ............ {
[36m(ActorModelRayActor pid=1115138)[0m     "enabled": false, [32m [repeated 3x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m     "start_step": null, 
[36m(ActorModelRayActor pid=1115138)[0m     "end_step": null, 
[36m(ActorModelRayActor pid=1115138)[0m     "metric_path": null, 
[36m(ActorModelRayActor pid=1115138)[0m     "arg_mappings": null, 
[36m(ActorModelRayActor pid=1115138)[0m     "metric": "throughput", 
[36m(ActorModelRayActor pid=1115138)[0m     "model_info": null, 
[36m(ActorModelRayActor pid=1115138)[0m     "results_dir": "autotuning_results", 
[36m(ActorModelRayActor pid=1115138)[0m     "exps_dir": "autotuning_exps", 
[36m(ActorModelRayActor pid=1115138)[0m     "overwrite": true, 
[36m(ActorModelRayActor pid=1115138)[0m     "fast": true, 
[36m(ActorModelRayActor pid=1115138)[0m     "start_profile_step": 3, 
[36m(ActorModelRayActor pid=1115138)[0m     "end_profile_step": 5, 
[36m(ActorModelRayActor pid=1115138)[0m     "tuner_type": "gridsearch", 
[36m(ActorModelRayActor pid=1115138)[0m     "tuner_early_stopping": 5, 
[36m(ActorModelRayActor pid=1115138)[0m     "tuner_num_trials": 50, 
[36m(ActorModelRayActor pid=1115138)[0m     "model_info_path": null, 
[36m(ActorModelRayActor pid=1115138)[0m     "mp_size": 1, 
[36m(ActorModelRayActor pid=1115138)[0m     "max_train_batch_size": null, 
[36m(ActorModelRayActor pid=1115138)[0m     "min_train_batch_size": 1, 
[36m(ActorModelRayActor pid=1115138)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(ActorModelRayActor pid=1115138)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(ActorModelRayActor pid=1115138)[0m     "num_tuning_micro_batch_sizes": 3
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   bfloat16_enabled ............. True
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   bfloat16_immediate_grad_update  True
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   checkpoint_parallel_write_pipeline  False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   checkpoint_tag_validation_enabled  True
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   checkpoint_tag_validation_fail  False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ac6f0243790>
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   communication_data_type ...... None
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   curriculum_enabled_legacy .... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   curriculum_params_legacy ..... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   data_efficiency_enabled ...... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   dataloader_drop_last ......... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   disable_allgather ............ False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   dump_state ................... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   dynamic_loss_scale_args ...... None
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   eigenvalue_enabled ........... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   eigenvalue_gas_boundary_resolution  1
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   eigenvalue_layer_num ......... 0
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   eigenvalue_max_iter .......... 100
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   eigenvalue_stability ......... 1e-06
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   eigenvalue_tol ............... 0.01
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   eigenvalue_verbose ........... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   elasticity_enabled ........... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   flops_profiler_config ........ {
[36m(ActorModelRayActor pid=1115138)[0m     "recompute_fwd_factor": 0.0, 
[36m(ActorModelRayActor pid=1115138)[0m     "profile_step": 1, 
[36m(ActorModelRayActor pid=1115138)[0m     "module_depth": -1, 
[36m(ActorModelRayActor pid=1115138)[0m     "top_modules": 1, 
[36m(ActorModelRayActor pid=1115138)[0m     "detailed": true, 
[36m(ActorModelRayActor pid=1115138)[0m     "output_file": null
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   fp16_auto_cast ............... None
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   fp16_enabled ................. False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   fp16_master_weights_and_gradients  False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,355] [INFO] [config.py:1007:print]   global_rank .................. 0
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   grad_accum_dtype ............. fp32
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   gradient_accumulation_steps .. 16
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   gradient_clipping ............ 1.0
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   gradient_predivide_factor .... 1.0
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   graph_harvesting ............. False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   initial_dynamic_scale ........ 1
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   load_universal_checkpoint .... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   loss_scale ................... 1.0
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   memory_breakdown ............. False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   mics_hierarchial_params_gather  False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   mics_shard_size .............. -1
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   nebula_config ................ {
[36m(ActorModelRayActor pid=1115138)[0m     "persistent_storage_path": null, 
[36m(ActorModelRayActor pid=1115138)[0m     "persistent_time_interval": 100, 
[36m(ActorModelRayActor pid=1115138)[0m     "num_of_version_in_retention": 2, 
[36m(ActorModelRayActor pid=1115138)[0m     "enable_nebula_load": true, 
[36m(ActorModelRayActor pid=1115138)[0m     "load_path": null
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   optimizer_legacy_fusion ...... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   optimizer_name ............... None
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   optimizer_params ............. None
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   pld_enabled .................. False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   pld_params ................... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   prescale_gradients ........... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   scheduler_name ............... None
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   scheduler_params ............. None
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   seq_parallel_communication_data_type  torch.float32
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   sparse_attention ............. None
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   sparse_gradients_enabled ..... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   steps_per_print .............. 100
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   timers_config ................ enabled=True synchronized=True
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   train_batch_size ............. 128
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   train_micro_batch_size_per_gpu  4
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   use_data_before_expert_parallel_  False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   use_node_local_storage ....... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   wall_clock_breakdown ......... False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   weight_quantization_config ... None
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,356] [INFO] [config.py:1007:print]   world_size ................... 2
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,357] [INFO] [config.py:1007:print]   zero_allow_untested_optimizer  False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,357] [INFO] [config.py:1007:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,357] [INFO] [config.py:1007:print]   zero_enabled ................. True
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,357] [INFO] [config.py:1007:print]   zero_force_ds_cpu_optimizer .. True
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,357] [INFO] [config.py:1007:print]   zero_optimization_stage ...... 3
[36m(ActorModelRayActor pid=1115138)[0m [2025-08-10 14:49:13,357] [INFO] [config.py:993:print_user_config]   json = {
[36m(ActorModelRayActor pid=1115138)[0m     "steps_per_print": 100, 
[36m(ActorModelRayActor pid=1115138)[0m     "zero_optimization": {
[36m(ActorModelRayActor pid=1115138)[0m         "stage": 3, 
[36m(ActorModelRayActor pid=1115138)[0m         "offload_param": {
[36m(ActorModelRayActor pid=1115138)[0m             "device": "none"
[36m(ActorModelRayActor pid=1115138)[0m     }, [32m [repeated 5x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m         "offload_optimizer": {
[36m(ActorModelRayActor pid=1115138)[0m             "device": "cpu", 
[36m(ActorModelRayActor pid=1115138)[0m             "pin_memory": true
[36m(ActorModelRayActor pid=1115138)[0m         "sub_group_size": "auto", 
[36m(ActorModelRayActor pid=1115138)[0m         "stage3_prefetch_bucket_size": "auto", [32m [repeated 4x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m         "reduce_bucket_size": "auto", 
[36m(ActorModelRayActor pid=1115138)[0m         "zero_hpz_partition_size": 1, 
[36m(ActorModelRayActor pid=1115138)[0m         "zero_quantized_weights": false, 
[36m(ActorModelRayActor pid=1115138)[0m         "zero_quantized_gradients": false
[36m(ActorModelRayActor pid=1115138)[0m     "bf16": {
[36m(ActorModelRayActor pid=1115138)[0m         "enabled": true
[36m(ActorModelRayActor pid=1115138)[0m     "gradient_clipping": 1.0, 
[36m(ActorModelRayActor pid=1115138)[0m     "prescale_gradients": false, 
[36m(ActorModelRayActor pid=1115138)[0m     "wall_clock_breakdown": false, 
[36m(ActorModelRayActor pid=1115138)[0m     "data_types": {
[36m(ActorModelRayActor pid=1115138)[0m         "grad_accum_dtype": "fp32"
[36m(ActorModelRayActor pid=1115138)[0m     "train_micro_batch_size_per_gpu": 4, 
[36m(ActorModelRayActor pid=1115138)[0m     "train_batch_size": 128
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:14,958] [INFO] [utils.py:781:see_memory_usage] Before creating fp16 partitions
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:18,037] [INFO] [utils.py:781:see_memory_usage] After creating fp16 partitions: 3
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:18,528] [INFO] [utils.py:781:see_memory_usage] Before creating fp32 partitions
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:18,549] [INFO] [utils.py:782:see_memory_usage] MA 2.87 GB         Max_MA 2.87 GB         CA 2.88 GB         Max_CA 3 GB [32m [repeated 6x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:18,549] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 184.38 GB, percent = 9.1%[32m [repeated 6x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:25,420] [INFO] [utils.py:781:see_memory_usage] After creating fp32 partitions
[36m(ActorModelRayActor pid=1116981)[0m Installed CUDA version 12.8 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
[36m(ActorModelRayActor pid=1116981)[0m ninja: no work to do.
[36m(ActorModelRayActor pid=1116981)[0m Time to load cpu_adam op: 2.5529630184173584 seconds
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:25,462] [INFO] [utils.py:782:see_memory_usage] MA 2.87 GB         Max_MA 2.87 GB         CA 2.88 GB         Max_CA 3 GB 
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:25,462] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 195.09 GB, percent = 9.7%
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:25,753] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:25,753] [INFO] [utils.py:782:see_memory_usage] MA 2.87 GB         Max_MA 2.87 GB         CA 2.88 GB         Max_CA 3 GB 
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:25,754] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 195.63 GB, percent = 9.7%
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:49:36 [gpu_model_runner.py:1686] Graph capturing finished in 34 secs, took 1.73 GiB
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:49:36 [core.py:159] init engine (profile, create kv cache, warmup model) took 98.87 seconds
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:49:36 [core_client.py:439] Core engine process 0 ready.
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:37,259] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:37,260] [INFO] [utils.py:782:see_memory_usage] MA 2.87 GB         Max_MA 2.87 GB         CA 2.88 GB         Max_CA 3 GB 
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:37,260] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 209.91 GB, percent = 10.4%
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:37,260] [INFO] [stage3.py:534:_setup_for_real_optimizer] optimizer state initialized
Successfully initialized 3 agents
workflow args {'template_id': 1, 'num_rounds': 2, 'max_others': 5, 'contain_self': True, 'shuffle_responses': True}
Multi-agent Reward Allocation {'self': <marti.verifiers.auto_reward_alloc.MultiAgentRewardAllocation object at 0x7a5bcbbb0460>, 'verify': 'math', 'name': 'margin', 'alpha': 0.5, 'beta': 0.5, 'args': (), 'kwargs': {'use_ttrl': False}}
Multi-agent Reward Allocation {'self': <marti.verifiers.auto_reward_alloc.MultiAgentRewardAllocation object at 0x7a5bcbbb0550>, 'verify': 'math', 'name': None, 'alpha': 0.5, 'beta': 0.5, 'args': (), 'kwargs': {}}
{'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
{'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
{'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
Warning: No outputs found for the agent (generator_1) in round 0.
[36m(LLMRayActor pid=1115131)[0m WARNING 08-10 14:49:46 [executor_base.py:215] Executor is not sleeping.
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:49:40 [gpu_model_runner.py:1686] Graph capturing finished in 38 secs, took 1.73 GiB[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:49:40 [core.py:159] init engine (profile, create kv cache, warmup model) took 102.58 seconds[32m [repeated 5x across cluster][0m
Warning: No outputs found for the agent (generator_2) in round 0.[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:49:40 [core_client.py:439] Core engine process 0 ready.[32m [repeated 5x across cluster][0m

[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,800] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,801] [INFO] [utils.py:782:see_memory_usage] MA 3.81 GB         Max_MA 4.97 GB         CA 4.97 GB         Max_CA 5 GB 
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,801] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 225.93 GB, percent = 11.2%
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,802] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer_Stage3Warning: No outputs found for the agent (generator_3) in round 0.

[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,802] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,802] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x795d0021e4d0>
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,802] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[[0.9, 0.95], [0.9, 0.95]]
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,803] [INFO] [config.py:1003:print] DeepSpeedEngine configuration:
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,803] [INFO] [config.py:1007:print]   activation_checkpointing_config  {
[36m(ActorModelRayActor pid=1115139)[0m     "partition_activations": false, 
[36m(ActorModelRayActor pid=1115139)[0m     "contiguous_memory_optimization": false, 
[36m(ActorModelRayActor pid=1115139)[0m     "cpu_checkpointing": false, 
[36m(ActorModelRayActor pid=1115139)[0m     "number_checkpoints": null, 
[36m(ActorModelRayActor pid=1115139)[0m     "synchronize_checkpoint_boundary": false, 
[36m(ActorModelRayActor pid=1115139)[0m     "profile": false
[36m(ActorModelRayActor pid=1115139)[0m }
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   amp_enabled .................. False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   amp_params ................... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   autotuning_config ............ {
[36m(ActorModelRayActor pid=1115139)[0m     "enabled": false, 
[36m(ActorModelRayActor pid=1115139)[0m     "start_step": null, 
[36m(ActorModelRayActor pid=1115139)[0m     "end_step": null, 
[36m(ActorModelRayActor pid=1115139)[0m     "metric_path": null, 
[36m(ActorModelRayActor pid=1115139)[0m     "arg_mappings": null, 
[36m(ActorModelRayActor pid=1115139)[0m     "metric": "throughput", 
[36m(ActorModelRayActor pid=1115139)[0m     "model_info": null, 
[36m(ActorModelRayActor pid=1115139)[0m     "results_dir": "autotuning_results", 
[36m(ActorModelRayActor pid=1115139)[0m     "exps_dir": "autotuning_exps", 
[36m(ActorModelRayActor pid=1115139)[0m     "overwrite": true, 
[36m(ActorModelRayActor pid=1115139)[0m     "fast": true, 
[36m(ActorModelRayActor pid=1115139)[0m     "start_profile_step": 3, 
[36m(ActorModelRayActor pid=1115139)[0m     "end_profile_step": 5, 
[36m(ActorModelRayActor pid=1115139)[0m     "tuner_type": "gridsearch", 
[36m(ActorModelRayActor pid=1115139)[0m     "tuner_early_stopping": 5, 
[36m(ActorModelRayActor pid=1115139)[0m     "tuner_num_trials": 50, 
[36m(ActorModelRayActor pid=1115139)[0m     "model_info_path": null, 
[36m(ActorModelRayActor pid=1115139)[0m     "mp_size": 1, 
[36m(ActorModelRayActor pid=1115139)[0m     "max_train_batch_size": null, 
[36m(ActorModelRayActor pid=1115139)[0m     "min_train_batch_size": 1, 
[36m(ActorModelRayActor pid=1115139)[0m     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
[36m(ActorModelRayActor pid=1115139)[0m     "min_train_micro_batch_size_per_gpu": 1, 
[36m(ActorModelRayActor pid=1115139)[0m     "num_tuning_micro_batch_sizes": 3
[36m(ActorModelRayActor pid=1115139)[0m }
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   bfloat16_enabled ............. True
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   bfloat16_immediate_grad_update  True
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   checkpoint_parallel_write_pipeline  False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   checkpoint_tag_validation_enabled  True
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   checkpoint_tag_validation_fail  False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x795d0021c220>
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   communication_data_type ...... None
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   curriculum_enabled_legacy .... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   curriculum_params_legacy ..... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   data_efficiency_enabled ...... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   dataloader_drop_last ......... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   disable_allgather ............ False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   dump_state ................... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   dynamic_loss_scale_args ...... None
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,804] [INFO] [config.py:1007:print]   eigenvalue_enabled ........... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   eigenvalue_gas_boundary_resolution  1
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   eigenvalue_layer_name ........ bert.encoder.layer
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   eigenvalue_layer_num ......... 0
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   eigenvalue_max_iter .......... 100
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   eigenvalue_stability ......... 1e-06
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   eigenvalue_tol ............... 0.01
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   eigenvalue_verbose ........... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   elasticity_enabled ........... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   flops_profiler_config ........ {
[36m(ActorModelRayActor pid=1115139)[0m     "enabled": false, 
[36m(ActorModelRayActor pid=1115139)[0m     "recompute_fwd_factor": 0.0, 
[36m(ActorModelRayActor pid=1115139)[0m     "profile_step": 1, 
[36m(ActorModelRayActor pid=1115139)[0m     "module_depth": -1, 
[36m(ActorModelRayActor pid=1115139)[0m     "top_modules": 1, 
[36m(ActorModelRayActor pid=1115139)[0m     "detailed": true, 
[36m(ActorModelRayActor pid=1115139)[0m     "output_file": null
[36m(ActorModelRayActor pid=1115139)[0m }
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   fp16_auto_cast ............... None
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   fp16_enabled ................. False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   fp16_master_weights_and_gradients  False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   global_rank .................. 0
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   grad_accum_dtype ............. fp32
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   gradient_accumulation_steps .. 16
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   gradient_clipping ............ 1.0
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   gradient_predivide_factor .... 1.0
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   graph_harvesting ............. False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   initial_dynamic_scale ........ 1
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   load_universal_checkpoint .... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   loss_scale ................... 1.0
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   memory_breakdown ............. False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   mics_hierarchial_params_gather  False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   mics_shard_size .............. -1
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   nebula_config ................ {
[36m(ActorModelRayActor pid=1115139)[0m     "enabled": false, 
[36m(ActorModelRayActor pid=1115139)[0m     "persistent_storage_path": null, 
[36m(ActorModelRayActor pid=1115139)[0m     "persistent_time_interval": 100, 
[36m(ActorModelRayActor pid=1115139)[0m     "num_of_version_in_retention": 2, 
[36m(ActorModelRayActor pid=1115139)[0m     "enable_nebula_load": true, 
[36m(ActorModelRayActor pid=1115139)[0m     "load_path": null
[36m(ActorModelRayActor pid=1115139)[0m }
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   optimizer_legacy_fusion ...... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   optimizer_name ............... None
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   optimizer_params ............. None
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,805] [INFO] [config.py:1007:print]   pld_enabled .................. False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   pld_params ................... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   prescale_gradients ........... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   scheduler_name ............... None
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   scheduler_params ............. None
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   seq_parallel_communication_data_type  torch.float32
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   sparse_attention ............. None
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   sparse_gradients_enabled ..... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   steps_per_print .............. 100
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   timers_config ................ enabled=True synchronized=True
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   train_batch_size ............. 128
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   train_micro_batch_size_per_gpu  4
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   use_data_before_expert_parallel_  False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   use_node_local_storage ....... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   wall_clock_breakdown ......... False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   weight_quantization_config ... None
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   world_size ................... 2
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   zero_allow_untested_optimizer  False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   zero_enabled ................. True
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   zero_force_ds_cpu_optimizer .. True
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:1007:print]   zero_optimization_stage ...... 3
[36m(ActorModelRayActor pid=1115139)[0m [2025-08-10 14:49:46,806] [INFO] [config.py:993:print_user_config]   json = {
[36m(ActorModelRayActor pid=1115139)[0m     "steps_per_print": 100, 
[36m(ActorModelRayActor pid=1115139)[0m     "zero_optimization": {
[36m(ActorModelRayActor pid=1115139)[0m         "stage": 3, 
[36m(ActorModelRayActor pid=1115139)[0m         "offload_param": {
[36m(ActorModelRayActor pid=1115139)[0m             "device": "none"
[36m(ActorModelRayActor pid=1115139)[0m         }, 
[36m(ActorModelRayActor pid=1115139)[0m         "offload_optimizer": {
[36m(ActorModelRayActor pid=1115139)[0m             "device": "cpu", 
[36m(ActorModelRayActor pid=1115139)[0m             "pin_memory": true
[36m(ActorModelRayActor pid=1115139)[0m         }, 
[36m(ActorModelRayActor pid=1115139)[0m         "sub_group_size": "auto", 
[36m(ActorModelRayActor pid=1115139)[0m         "stage3_max_live_parameters": "auto", 
[36m(ActorModelRayActor pid=1115139)[0m         "stage3_max_reuse_distance": "auto", 
[36m(ActorModelRayActor pid=1115139)[0m         "stage3_param_persistence_threshold": "auto", 
[36m(ActorModelRayActor pid=1115139)[0m         "stage3_prefetch_bucket_size": "auto", 
[36m(ActorModelRayActor pid=1115139)[0m         "reduce_bucket_size": "auto", 
[36m(ActorModelRayActor pid=1115139)[0m         "zero_hpz_partition_size": 1, 
[36m(ActorModelRayActor pid=1115139)[0m         "zero_quantized_weights": false, 
[36m(ActorModelRayActor pid=1115139)[0m         "zero_quantized_gradients": false
[36m(ActorModelRayActor pid=1115139)[0m     }, 
[36m(ActorModelRayActor pid=1115139)[0m     "bf16": {
[36m(ActorModelRayActor pid=1115139)[0m         "enabled": true
[36m(ActorModelRayActor pid=1115139)[0m     }, 
[36m(ActorModelRayActor pid=1115139)[0m     "gradient_clipping": 1.0, 
[36m(ActorModelRayActor pid=1115139)[0m     "prescale_gradients": false, 
[36m(ActorModelRayActor pid=1115139)[0m     "wall_clock_breakdown": false, 
[36m(ActorModelRayActor pid=1115139)[0m     "data_types": {
[36m(ActorModelRayActor pid=1115139)[0m         "grad_accum_dtype": "fp32"
[36m(ActorModelRayActor pid=1115139)[0m     }, 
[36m(ActorModelRayActor pid=1115139)[0m     "train_micro_batch_size_per_gpu": 4, 
[36m(ActorModelRayActor pid=1115139)[0m     "train_batch_size": 128
[36m(ActorModelRayActor pid=1115139)[0m }
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:   0%|          | 0/250 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(ActorModelRayActor pid=1116981)[0m 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
[36m(ActorModelRayActor pid=1115139)[0m 
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.73it/s]
[36m(ActorModelRayActor pid=1116981)[0m 
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.28it/s]
[36m(ActorModelRayActor pid=1116981)[0m Using /home/ubuntu/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
[36m(ActorModelRayActor pid=1116981)[0m Detected CUDA files, patching ldflags
[36m(ActorModelRayActor pid=1116981)[0m Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
[36m(ActorModelRayActor pid=1116981)[0m /home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[36m(ActorModelRayActor pid=1116981)[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
[36m(ActorModelRayActor pid=1116981)[0m   warnings.warn(
[36m(ActorModelRayActor pid=1116981)[0m Building extension module cpu_adam...
[36m(ActorModelRayActor pid=1116981)[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[36m(ActorModelRayActor pid=1116981)[0m Loading extension module cpu_adam...
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:   0%|          | 1/250 [00:01<04:53,  1.18s/it, est. speed input: 42.43 toks/s, output: 28.85 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:   0%|          | 0/250 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  26%|██▋       | 66/250 [00:05<00:06, 29.21it/s, est. speed input: 903.40 toks/s, output: 2532.22 toks/s]
Processed prompts:  30%|██▉       | 74/250 [00:06<00:04, 40.39it/s, est. speed input: 986.13 toks/s, output: 2923.58 toks/s]
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  35%|███▍      | 87/250 [00:06<00:06, 25.08it/s, est. speed input: 1122.24 toks/s, output: 3360.89 toks/s][32m [repeated 147x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  65%|██████▍   | 162/250 [00:10<00:10,  8.15it/s, est. speed input: 1431.96 toks/s, output: 5173.05 toks/s]
Processed prompts:  66%|██████▌   | 165/250 [00:10<00:07, 11.00it/s, est. speed input: 1449.22 toks/s, output: 5298.11 toks/s][32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  73%|███████▎  | 182/250 [00:11<00:03, 18.82it/s, est. speed input: 1539.32 toks/s, output: 5833.68 toks/s][32m [repeated 150x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  68%|██████▊   | 171/250 [00:11<00:07, 10.33it/s, est. speed input: 1451.65 toks/s, output: 5573.09 toks/s]
Processed prompts:  70%|██████▉   | 174/250 [00:11<00:05, 12.95it/s, est. speed input: 1459.47 toks/s, output: 5702.97 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  88%|████████▊ | 221/250 [00:16<00:03,  8.02it/s, est. speed input: 1366.62 toks/s, output: 6246.80 toks/s][32m [repeated 97x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  88%|████████▊ | 219/250 [00:16<00:06,  5.14it/s, est. speed input: 1315.06 toks/s, output: 5957.93 toks/s]
Processed prompts:  88%|████████▊ | 221/250 [00:16<00:04,  6.61it/s, est. speed input: 1317.96 toks/s, output: 6036.33 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  92%|█████████▏| 229/250 [00:18<00:03,  6.59it/s, est. speed input: 1292.07 toks/s, output: 6001.73 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  93%|█████████▎| 232/250 [00:18<00:01,  9.36it/s, est. speed input: 1300.52 toks/s, output: 6143.28 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  91%|█████████ | 227/250 [00:18<00:02,  8.56it/s, est. speed input: 1247.48 toks/s, output: 6057.33 toks/s][32m [repeated 35x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  96%|█████████▋| 241/250 [00:23<00:06,  1.44it/s, est. speed input: 1049.66 toks/s, output: 5502.00 toks/s][32m [repeated 41x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  95%|█████████▌| 238/250 [00:29<00:19,  1.64s/it, est. speed input: 855.04 toks/s, output: 4224.65 toks/s][32m [repeated 10x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  98%|█████████▊| 244/250 [00:34<00:16,  2.83s/it, est. speed input: 738.38 toks/s, output: 4027.38 toks/s][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  97%|█████████▋| 242/250 [00:39<00:19,  2.42s/it, est. speed input: 635.97 toks/s, output: 3416.62 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  98%|█████████▊| 245/250 [00:42<00:21,  4.29s/it, est. speed input: 604.67 toks/s, output: 3380.74 toks/s]
Processed prompts: 100%|██████████| 250/250 [00:42<00:00,  5.93it/s, est. speed input: 617.01 toks/s, output: 3865.42 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:   0%|          | 0/250 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:   0%|          | 1/250 [00:16<1:06:58, 16.14s/it, est. speed input: 44.92 toks/s, output: 2.17 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  97%|█████████▋| 243/250 [00:40<00:27,  3.97s/it, est. speed input: 615.45 toks/s, output: 3392.46 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  96%|█████████▌| 240/250 [00:43<00:41,  4.15s/it, est. speed input: 578.71 toks/s, output: 3003.13 toks/s]
Processed prompts: 100%|██████████| 250/250 [00:43<00:00,  5.77it/s, est. speed input: 612.58 toks/s, output: 3946.65 toks/s][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:   0%|          | 0/250 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:   6%|▌         | 14/250 [00:21<01:10,  3.33it/s, est. speed input: 1033.01 toks/s, output: 69.82 toks/s][32m [repeated 64x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  30%|██▉       | 74/250 [00:26<00:13, 13.40it/s, est. speed input: 3489.01 toks/s, output: 631.85 toks/s][32m [repeated 135x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  48%|████▊     | 120/250 [00:31<00:11, 11.63it/s, est. speed input: 5610.61 toks/s, output: 1158.79 toks/s][32m [repeated 131x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  62%|██████▏   | 156/250 [00:36<00:11,  8.14it/s, est. speed input: 6834.97 toks/s, output: 1551.72 toks/s][32m [repeated 105x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  68%|██████▊   | 170/250 [00:36<00:09,  8.20it/s, est. speed input: 7673.71 toks/s, output: 1774.63 toks/s]
Processed prompts:  69%|██████▉   | 172/250 [00:36<00:07, 10.17it/s, est. speed input: 7883.53 toks/s, output: 1807.92 toks/s]
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  74%|███████▍  | 185/250 [00:41<00:11,  5.87it/s, est. speed input: 7788.62 toks/s, output: 1899.50 toks/s][32m [repeated 109x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  87%|████████▋ | 217/250 [00:46<00:08,  3.73it/s, est. speed input: 8872.31 toks/s, output: 2345.20 toks/s][32m [repeated 76x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  86%|████████▌ | 215/250 [00:48<00:11,  2.94it/s, est. speed input: 8499.53 toks/s, output: 2300.04 toks/s]
Processed prompts:  86%|████████▋ | 216/250 [00:48<00:09,  3.58it/s, est. speed input: 8511.96 toks/s, output: 2324.14 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  92%|█████████▏| 229/250 [00:51<00:11,  1.85it/s, est. speed input: 8810.74 toks/s, output: 2448.36 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  92%|█████████▏| 230/250 [00:51<00:09,  2.11it/s, est. speed input: 8812.43 toks/s, output: 2469.42 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  91%|█████████ | 227/250 [00:51<00:14,  1.63it/s, est. speed input: 8527.31 toks/s, output: 2407.41 toks/s][32m [repeated 47x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  92%|█████████▏| 231/250 [00:53<00:14,  1.29it/s, est. speed input: 8597.83 toks/s, output: 2430.76 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  93%|█████████▎| 232/250 [00:53<00:12,  1.45it/s, est. speed input: 8565.47 toks/s, output: 2445.71 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  92%|█████████▏| 231/250 [00:56<00:13,  1.46it/s, est. speed input: 8288.26 toks/s, output: 2369.34 toks/s][32m [repeated 7x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  88%|████████▊ | 221/250 [00:56<00:41,  1.45s/it, est. speed input: 7268.70 toks/s, output: 2150.51 toks/s][32m [repeated 11x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  92%|█████████▏| 231/250 [01:01<00:24,  1.30s/it, est. speed input: 7360.26 toks/s, output: 2199.43 toks/s][32m [repeated 19x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  90%|████████▉ | 224/250 [01:01<00:45,  1.75s/it, est. speed input: 6791.81 toks/s, output: 2082.67 toks/s][32m [repeated 4x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  96%|█████████▌| 239/250 [01:05<00:13,  1.22s/it, est. speed input: 7271.46 toks/s, output: 2358.05 toks/s][32m [repeated 10x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  90%|█████████ | 225/250 [01:07<01:07,  2.69s/it, est. speed input: 6438.30 toks/s, output: 1950.40 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  96%|█████████▋| 241/250 [01:12<00:22,  2.45s/it, est. speed input: 6696.96 toks/s, output: 2216.15 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  91%|█████████ | 228/250 [01:13<00:50,  2.29s/it, est. speed input: 5954.07 toks/s, output: 1914.41 toks/s][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts: 100%|██████████| 250/250 [01:18<00:00,  3.20it/s, est. speed input: 6836.93 toks/s, output: 2437.80 toks/s][32m [repeated 11x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  91%|█████████ | 228/250 [01:16<00:58,  2.66s/it, est. speed input: 5870.11 toks/s, output: 1854.51 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts: 100%|█████████▉| 249/250 [01:20<00:00,  1.67it/s, est. speed input: 6647.00 toks/s, output: 2440.69 toks/s]
Processed prompts: 100%|██████████| 250/250 [01:20<00:00,  3.12it/s, est. speed input: 6760.00 toks/s, output: 2491.86 toks/s]
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  92%|█████████▏| 231/250 [01:23<01:03,  3.36s/it, est. speed input: 5414.17 toks/s, output: 1804.08 toks/s][32m [repeated 10x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts: 100%|██████████| 250/250 [01:21<00:00,  1.35it/s, est. speed input: 6548.11 toks/s, output: 2498.65 toks/s]
Processed prompts: 100%|██████████| 250/250 [01:21<00:00,  3.07it/s, est. speed input: 6548.11 toks/s, output: 2498.65 toks/s]
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts: 100%|█████████▉| 249/250 [01:26<00:00,  3.52it/s, est. speed input: 6181.25 toks/s, output: 2611.03 toks/s]
Processed prompts: 100%|██████████| 250/250 [01:26<00:00,  2.89it/s, est. speed input: 6263.08 toks/s, output: 2658.44 toks/s]
{'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
{'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
{'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
Warning: No outputs found for the agent (generator_1) in round 0.
Warning: No outputs found for the agent (generator_2) in round 0.
Warning: No outputs found for the agent (generator_3) in round 0.
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  97%|█████████▋| 242/250 [01:26<00:04,  1.82it/s, est. speed input: 5795.44 toks/s, output: 2264.81 toks/s][32m [repeated 7x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  99%|█████████▉| 248/250 [01:26<00:00,  3.32it/s, est. speed input: 6139.70 toks/s, output: 2545.31 toks/s]
Processed prompts: 100%|██████████| 250/250 [01:26<00:00,  2.88it/s, est. speed input: 6235.90 toks/s, output: 2639.20 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:   7%|▋         | 1/15 [00:02<00:33,  2.42s/it, est. speed input: 33.92 toks/s, output: 123.70 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  67%|██████▋   | 10/15 [00:07<00:02,  1.98it/s, est. speed input: 217.50 toks/s, output: 856.37 toks/s][32m [repeated 40x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  93%|█████████▎| 14/15 [00:11<00:00,  1.12it/s, est. speed input: 192.11 toks/s, output: 917.35 toks/s] 
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  67%|██████▋   | 10/15 [00:12<00:09,  1.83s/it, est. speed input: 126.18 toks/s, output: 501.61 toks/s][32m [repeated 19x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  93%|█████████▎| 14/15 [00:13<00:01,  1.07s/it, est. speed input: 168.61 toks/s, output: 825.85 toks/s][32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts: 100%|██████████| 15/15 [00:25<00:00,  4.31s/it, est. speed input: 93.14 toks/s, output: 550.10 toks/s] 
Processed prompts: 100%|██████████| 15/15 [00:25<00:00,  1.67s/it, est. speed input: 93.14 toks/s, output: 550.10 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  80%|████████  | 12/15 [00:17<00:06,  2.26s/it, est. speed input: 115.78 toks/s, output: 542.38 toks/s][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  93%|█████████▎| 14/15 [00:17<00:01,  1.67s/it, est. speed input: 125.63 toks/s, output: 654.76 toks/s][32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts: 100%|██████████| 15/15 [00:30<00:00,  5.87s/it, est. speed input: 76.98 toks/s, output: 478.03 toks/s] 
Processed prompts: 100%|██████████| 15/15 [00:30<00:00,  2.02s/it, est. speed input: 76.98 toks/s, output: 478.03 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts: 100%|██████████| 15/15 [00:38<00:00,  6.94s/it, est. speed input: 62.60 toks/s, output: 384.16 toks/s] 
Processed prompts: 100%|██████████| 15/15 [00:38<00:00,  2.54s/it, est. speed input: 62.60 toks/s, output: 384.16 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  87%|████████▋ | 13/15 [00:38<00:15,  7.69s/it, est. speed input: 56.21 toks/s, output: 351.76 toks/s] 
Processed prompts: 100%|██████████| 15/15 [00:38<00:00,  2.57s/it, est. speed input: 61.77 toks/s, output: 563.94 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:   7%|▋         | 1/15 [00:01<00:25,  1.83s/it, est. speed input: 2322.35 toks/s, output: 30.03 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts: 100%|██████████| 15/15 [00:38<00:00,  7.03s/it, est. speed input: 62.11 toks/s, output: 410.61 toks/s] 
Processed prompts: 100%|██████████| 15/15 [00:38<00:00,  2.56s/it, est. speed input: 62.11 toks/s, output: 410.61 toks/s][32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  33%|███▎      | 5/15 [00:07<00:09,  1.08it/s, est. speed input: 1533.25 toks/s, output: 306.90 toks/s][32m [repeated 22x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  60%|██████    | 9/15 [00:12<00:07,  1.18s/it, est. speed input: 1683.72 toks/s, output: 438.98 toks/s][32m [repeated 32x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  87%|████████▋ | 13/15 [00:18<00:04,  2.01s/it, est. speed input: 2271.49 toks/s, output: 481.50 toks/s][32m [repeated 11x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  93%|█████████▎| 14/15 [00:20<00:01,  1.92s/it, est. speed input: 2287.42 toks/s, output: 531.48 toks/s]
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts: 100%|██████████| 15/15 [00:29<00:00,  3.86s/it, est. speed input: 1613.88 toks/s, output: 414.83 toks/s]
Processed prompts: 100%|██████████| 15/15 [00:29<00:00,  1.95s/it, est. speed input: 1613.88 toks/s, output: 414.83 toks/s]
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  87%|████████▋ | 13/15 [00:21<00:04,  2.40s/it, est. speed input: 1575.86 toks/s, output: 502.28 toks/s][32m [repeated 4x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  93%|█████████▎| 14/15 [00:22<00:03,  3.10s/it, est. speed input: 1640.79 toks/s, output: 489.67 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  93%|█████████▎| 14/15 [00:32<00:05,  5.27s/it, est. speed input: 1415.42 toks/s, output: 366.76 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts: 100%|██████████| 15/15 [00:35<00:00,  6.16s/it, est. speed input: 1325.50 toks/s, output: 402.97 toks/s]
Processed prompts: 100%|██████████| 15/15 [00:35<00:00,  2.38s/it, est. speed input: 1325.50 toks/s, output: 402.97 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  80%|████████  | 12/15 [00:33<00:19,  6.57s/it, est. speed input: 1069.92 toks/s, output: 297.64 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  87%|████████▋ | 13/15 [00:36<00:10,  5.46s/it, est. speed input: 1054.76 toks/s, output: 362.60 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts: 100%|██████████| 15/15 [00:43<00:00,  7.99s/it, est. speed input: 1260.08 toks/s, output: 337.66 toks/s]
Processed prompts: 100%|██████████| 15/15 [00:43<00:00,  2.92s/it, est. speed input: 1260.08 toks/s, output: 337.66 toks/s]
{'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
{'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
{'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
Warning: No outputs found for the agent (generator_1) in round 0.
Warning: No outputs found for the agent (generator_2) in round 0.
Warning: No outputs found for the agent (generator_3) in round 0.
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:   0%|          | 0/42 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:   2%|▏         | 1/41 [00:02<01:33,  2.35s/it, est. speed input: 47.68 toks/s, output: 111.96 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  93%|█████████▎| 14/15 [00:46<00:06,  6.95s/it, est. speed input: 1016.00 toks/s, output: 369.46 toks/s]
Processed prompts: 100%|██████████| 15/15 [00:46<00:00,  3.11s/it, est. speed input: 1181.75 toks/s, output: 457.16 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:   0%|          | 0/41 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  64%|██████▍   | 27/42 [00:07<00:02,  5.01it/s, est. speed input: 499.59 toks/s, output: 2060.01 toks/s][32m [repeated 87x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  88%|████████▊ | 37/42 [00:12<00:03,  1.31it/s, est. speed input: 379.12 toks/s, output: 1935.12 toks/s][32m [repeated 60x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  93%|█████████▎| 39/42 [00:14<00:02,  1.16it/s, est. speed input: 357.04 toks/s, output: 2134.99 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  88%|████████▊ | 36/41 [00:17<00:07,  1.42s/it, est. speed input: 238.15 toks/s, output: 1597.85 toks/s][32m [repeated 11x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  93%|█████████▎| 38/41 [00:19<00:03,  1.24s/it, est. speed input: 238.63 toks/s, output: 1644.89 toks/s][32m [repeated 7x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  90%|█████████ | 37/41 [00:19<00:06,  1.59s/it, est. speed input: 220.11 toks/s, output: 1529.57 toks/s]
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts: 100%|██████████| 42/42 [00:24<00:00,  2.18s/it, est. speed input: 229.10 toks/s, output: 1408.01 toks/s]
Processed prompts: 100%|██████████| 42/42 [00:24<00:00,  1.71it/s, est. speed input: 229.10 toks/s, output: 1408.01 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  93%|█████████▎| 38/41 [00:23<00:06,  2.33s/it, est. speed input: 187.90 toks/s, output: 1363.58 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts: 100%|██████████| 42/42 [00:38<00:00,  6.98s/it, est. speed input: 144.83 toks/s, output: 981.97 toks/s] 
Processed prompts: 100%|██████████| 42/42 [00:38<00:00,  1.08it/s, est. speed input: 144.83 toks/s, output: 981.97 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  98%|█████████▊| 40/41 [00:38<00:06,  6.95s/it, est. speed input: 122.06 toks/s, output: 842.18 toks/s] 
Processed prompts: 100%|██████████| 41/41 [00:38<00:00,  1.05it/s, est. speed input: 124.53 toks/s, output: 947.38 toks/s]
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:   0%|          | 0/42 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:   2%|▏         | 1/42 [00:03<02:41,  3.94s/it, est. speed input: 853.05 toks/s, output: 9.91 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  95%|█████████▌| 39/41 [00:40<00:13,  6.71s/it, est. speed input: 113.12 toks/s, output: 894.54 toks/s] 
Processed prompts: 100%|██████████| 41/41 [00:40<00:00,  1.00it/s, est. speed input: 118.27 toks/s, output: 1094.71 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:   0%|          | 0/41 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  17%|█▋        | 7/41 [00:09<00:24,  1.41it/s, est. speed input: 2409.51 toks/s, output: 193.77 toks/s][32m [repeated 29x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  43%|████▎     | 18/42 [00:14<00:08,  2.99it/s, est. speed input: 2468.05 toks/s, output: 594.54 toks/s][32m [repeated 59x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  73%|███████▎  | 30/41 [00:19<00:04,  2.40it/s, est. speed input: 4387.48 toks/s, output: 944.77 toks/s][32m [repeated 66x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  86%|████████▌ | 36/42 [00:24<00:08,  1.40s/it, est. speed input: 4087.44 toks/s, output: 1022.17 toks/s][32m [repeated 13x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  90%|█████████ | 38/42 [00:32<00:11,  2.89s/it, est. speed input: 3225.79 toks/s, output: 872.13 toks/s] [32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  93%|█████████▎| 39/42 [00:33<00:07,  2.39s/it, est. speed input: 3214.64 toks/s, output: 923.25 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  88%|████████▊ | 36/41 [00:37<00:15,  3.13s/it, est. speed input: 2920.83 toks/s, output: 800.72 toks/s][32m [repeated 10x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  93%|█████████▎| 38/41 [00:35<00:04,  1.50s/it, est. speed input: 3057.14 toks/s, output: 940.89 toks/s][32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  90%|█████████ | 37/41 [00:43<00:15,  3.77s/it, est. speed input: 2635.24 toks/s, output: 773.45 toks/s][32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  95%|█████████▌| 39/41 [00:46<00:05,  2.71s/it, est. speed input: 2579.13 toks/s, output: 869.89 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  95%|█████████▌| 40/42 [00:49<00:12,  6.13s/it, est. speed input: 2193.60 toks/s, output: 701.31 toks/s]
Processed prompts: 100%|██████████| 42/42 [00:49<00:00,  1.18s/it, est. speed input: 2464.86 toks/s, output: 865.64 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  98%|█████████▊| 40/41 [00:52<00:04,  4.22s/it, est. speed input: 2419.76 toks/s, output: 797.73 toks/s][32m [repeated 6x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:55:06 [block_pool.py:264] Successfully reset prefix cache
[36m(LLMRayActor pid=1115132)[0m WARNING 08-10 14:49:46 [executor_base.py:215] Executor is not sleeping.[32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m INFO 08-10 14:55:14 [block_pool.py:264] Successfully reset prefix cache[32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:55:14 [gpu_worker.py:95] Sleep mode freed 36.30 GiB memory, 13.10 GiB memory is still in use.
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:55:14 [executor_base.py:210] It took 7.940184 seconds to fall asleep.
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:55:14 [block_pool.py:264] Successfully reset prefix cache
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:55:23 [gpu_worker.py:95] Sleep mode freed 43.27 GiB memory, 13.10 GiB memory is still in use.[32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m INFO 08-10 14:55:23 [executor_base.py:210] It took 9.528933 seconds to fall asleep.[32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:55:24 [block_pool.py:264] Successfully reset prefix cache

Episode [1/5]:   0%|          | 0/69 [00:00<?, ?it/s][36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:55:32 [gpu_worker.py:95] Sleep mode freed 36.30 GiB memory, 13.10 GiB memory is still in use.[32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:55:32 [executor_base.py:210] It took 8.150577 seconds to fall asleep.[32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m INFO 08-10 14:55:24 [block_pool.py:264] Successfully reset prefix cache
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:55:35 [executor_base.py:226] It took 2.787623 seconds to wake up tags {'weights', 'kv_cache'}.
[36m(LLMRayActor pid=1115135)[0m INFO 08-10 14:55:35 [executor_base.py:226] It took 0.519721 seconds to wake up tags {'kv_cache', 'weights'}.
[36m(generate_samples_remote pid=1114552)[0m INFO 08-10 14:55:39 [__init__.py:239] Automatically detected platform cuda.
[36m(LLMRayActor pid=1115133)[0m INFO 08-10 14:55:32 [gpu_worker.py:95] Sleep mode freed 36.30 GiB memory, 13.10 GiB memory is still in use.
[36m(LLMRayActor pid=1115133)[0m INFO 08-10 14:55:32 [executor_base.py:210] It took 8.155063 seconds to fall asleep.
[36m(generate_samples_remote pid=1114552)[0m /home/ubuntu/.local/lib/python3.10/site-packages/class_registry/entry_points.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(generate_samples_remote pid=1114552)[0m   from pkg_resources import iter_entry_points
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts: 100%|██████████| 41/41 [00:52<00:00,  3.14s/it, est. speed input: 2496.12 toks/s, output: 866.81 toks/s]
Processed prompts: 100%|██████████| 41/41 [00:52<00:00,  1.29s/it, est. speed input: 2496.12 toks/s, output: 866.81 toks/s][32m [repeated 3x across cluster][0m
[36m(generate_samples_remote pid=1114552)[0m [2025-08-10 14:55:42,417] [WARNING] [real_accelerator.py:194:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 14:55:36 [executor_base.py:226] It took 0.500774 seconds to wake up tags {'weights', 'kv_cache'}.[32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m INFO 08-10 14:55:36 [executor_base.py:226] It took 0.499610 seconds to wake up tags {'kv_cache', 'weights'}.
[36m(generate_samples_remote pid=1114552)[0m [2025-08-10 14:55:42,419] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cpu (auto detect)
[36m(generate_samples_remote pid=1114552)[0m {'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
[36m(generate_samples_remote pid=1114552)[0m {'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
[36m(generate_samples_remote pid=1114552)[0m {'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}
[36m(generate_samples_remote pid=1114552)[0m Warning: No outputs found for the agent (generator_1) in round 0.
[36m(generate_samples_remote pid=1114552)[0m Warning: No outputs found for the agent (generator_2) in round 0.
[36m(generate_samples_remote pid=1114552)[0m Warning: No outputs found for the agent (generator_3) in round 0.
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(generate_samples_remote pid=1114553)[0m INFO 08-10 14:55:40 [__init__.py:239] Automatically detected platform cuda.
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:   0%|          | 1/256 [00:00<03:13,  1.32it/s, est. speed input: 90.79 toks/s, output: 26.32 toks/s]
[36m(generate_samples_remote pid=1114553)[0m /home/ubuntu/.local/lib/python3.10/site-packages/class_registry/entry_points.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(generate_samples_remote pid=1114553)[0m   from pkg_resources import iter_entry_points
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][32m [repeated 5x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  23%|██▎       | 58/256 [00:05<00:07, 26.03it/s, est. speed input: 1009.50 toks/s, output: 2213.41 toks/s][32m [repeated 136x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  67%|██████▋   | 171/256 [00:10<00:03, 23.57it/s, est. speed input: 1795.92 toks/s, output: 6634.30 toks/s][32m [repeated 181x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  90%|█████████ | 231/256 [00:14<00:02, 12.33it/s, est. speed input: 1312.31 toks/s, output: 8125.97 toks/s]
Processed prompts:  91%|█████████ | 233/256 [00:14<00:01, 13.70it/s, est. speed input: 1315.74 toks/s, output: 8220.79 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  92%|█████████▏| 235/256 [00:14<00:01, 14.42it/s, est. speed input: 1316.12 toks/s, output: 8307.19 toks/s]
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  91%|█████████ | 233/256 [00:15<00:02,  9.60it/s, est. speed input: 1748.96 toks/s, output: 8124.55 toks/s][32m [repeated 125x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  98%|█████████▊| 252/256 [00:19<00:01,  3.39it/s, est. speed input: 1515.42 toks/s, output: 7692.89 toks/s][32m [repeated 55x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  98%|█████████▊| 250/256 [00:24<00:05,  1.18it/s, est. speed input: 834.82 toks/s, output: 5990.86 toks/s][32m [repeated 15x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  98%|█████████▊| 252/256 [00:30<00:07,  1.79s/it, est. speed input: 682.70 toks/s, output: 5055.11 toks/s][32m [repeated 9x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  99%|█████████▉| 253/256 [00:36<00:08,  2.90s/it, est. speed input: 821.61 toks/s, output: 4308.43 toks/s][32m [repeated 7x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts: 100%|██████████| 256/256 [00:38<00:00,  4.27s/it, est. speed input: 789.52 toks/s, output: 4254.07 toks/s] 
Processed prompts: 100%|██████████| 256/256 [00:38<00:00,  6.71it/s, est. speed input: 789.52 toks/s, output: 4254.07 toks/s]
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:   0%|          | 1/256 [00:01<04:17,  1.01s/it, est. speed input: 61.40 toks/s, output: 17.82 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:   1%|          | 2/256 [00:01<02:28,  1.71it/s, est. speed input: 290.43 toks/s, output: 42.48 toks/s]
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:   1%|          | 3/256 [00:01<01:53,  2.23it/s, est. speed input: 349.63 toks/s, output: 69.42 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  98%|█████████▊| 252/256 [00:40<00:16,  4.13s/it, est. speed input: 517.87 toks/s, output: 3856.49 toks/s][32m [repeated 4x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  99%|█████████▉| 253/256 [00:39<00:08,  2.87s/it, est. speed input: 751.01 toks/s, output: 3989.86 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:39<00:00,  6.43it/s, est. speed input: 756.98 toks/s, output: 4297.65 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][32m [repeated 4x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  12%|█▏        | 30/256 [00:06<00:27,  8.32it/s, est. speed input: 494.79 toks/s, output: 863.34 toks/s][32m [repeated 65x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  99%|█████████▉| 253/256 [00:42<00:11,  3.71s/it, est. speed input: 489.11 toks/s, output: 3708.59 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  27%|██▋       | 68/256 [00:07<00:07, 24.28it/s, est. speed input: 786.19 toks/s, output: 1905.98 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:07<00:05, 31.78it/s, est. speed input: 865.23 toks/s, output: 2131.20 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  99%|█████████▉| 254/256 [00:43<00:05,  2.87s/it, est. speed input: 481.01 toks/s, output: 3728.14 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:43<00:00,  5.87it/s, est. speed input: 485.21 toks/s, output: 3914.96 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  55%|█████▌    | 141/256 [00:10<00:03, 35.79it/s, est. speed input: 1335.79 toks/s, output: 4395.67 toks/s][32m [repeated 163x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  73%|███████▎  | 188/256 [00:12<00:02, 23.01it/s, est. speed input: 1545.83 toks/s, output: 5955.61 toks/s]
Processed prompts:  75%|███████▍  | 191/256 [00:12<00:02, 24.09it/s, est. speed input: 1558.61 toks/s, output: 6069.01 toks/s][32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  92%|█████████▏| 235/256 [00:14<00:01, 20.86it/s, est. speed input: 1694.78 toks/s, output: 7440.54 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  93%|█████████▎| 238/256 [00:15<00:01, 14.53it/s, est. speed input: 1682.17 toks/s, output: 7446.99 toks/s]
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  90%|█████████ | 231/256 [00:16<00:02, 10.73it/s, est. speed input: 1489.17 toks/s, output: 7079.80 toks/s][32m [repeated 162x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  95%|█████████▌| 244/256 [00:19<00:01,  8.46it/s, est. speed input: 1449.02 toks/s, output: 6808.20 toks/s][32m [repeated 38x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  88%|████████▊ | 224/256 [00:16<00:03,  8.62it/s, est. speed input: 1610.40 toks/s, output: 6797.95 toks/s][32m [repeated 44x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  98%|█████████▊| 251/256 [00:25<00:05,  1.04s/it, est. speed input: 1132.16 toks/s, output: 5570.44 toks/s][32m [repeated 22x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  91%|█████████ | 233/256 [00:17<00:03,  7.29it/s, est. speed input: 1556.18 toks/s, output: 6932.40 toks/s][32m [repeated 6x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  96%|█████████▋| 247/256 [00:26<00:09,  1.04s/it, est. speed input: 1097.87 toks/s, output: 5436.16 toks/s][32m [repeated 12x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  98%|█████████▊| 251/256 [00:35<00:14,  2.88s/it, est. speed input: 774.46 toks/s, output: 3899.32 toks/s][32m [repeated 6x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts: 100%|██████████| 256/256 [00:38<00:00,  3.43s/it, est. speed input: 719.54 toks/s, output: 3690.31 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:38<00:00,  6.65it/s, est. speed input: 719.54 toks/s, output: 3690.31 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  98%|█████████▊| 252/256 [00:40<00:10,  2.62s/it, est. speed input: 681.97 toks/s, output: 3802.18 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  98%|█████████▊| 252/256 [00:40<00:16,  4.24s/it, est. speed input: 729.29 toks/s, output: 3760.64 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:40<00:00,  6.26it/s, est. speed input: 735.73 toks/s, output: 4159.21 toks/s][32m [repeated 4x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][32m [repeated 4x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  98%|█████████▊| 250/256 [00:39<00:18,  3.01s/it, est. speed input: 734.14 toks/s, output: 3853.58 toks/s][32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:   0%|          | 1/256 [00:11<48:28, 11.40s/it, est. speed input: 152.83 toks/s, output: 1.84 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  98%|█████████▊| 251/256 [00:43<00:16,  3.28s/it, est. speed input: 670.85 toks/s, output: 3602.51 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:43<00:00,  5.88it/s, est. speed input: 690.70 toks/s, output: 4071.50 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:   5%|▌         | 14/256 [00:18<01:41,  2.39it/s, est. speed input: 1872.92 toks/s, output: 48.24 toks/s][32m [repeated 37x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  17%|█▋        | 43/256 [00:24<00:22,  9.55it/s, est. speed input: 3636.76 toks/s, output: 298.37 toks/s][32m [repeated 82x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  39%|███▊      | 99/256 [00:26<00:12, 12.23it/s, est. speed input: 6565.95 toks/s, output: 863.96 toks/s]
Processed prompts:  39%|███▉      | 101/256 [00:26<00:11, 13.42it/s, est. speed input: 6635.71 toks/s, output: 891.24 toks/s]
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  34%|███▎      | 86/256 [00:28<00:18,  9.01it/s, est. speed input: 5522.57 toks/s, output: 741.25 toks/s][32m [repeated 129x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  63%|██████▎   | 161/256 [00:33<00:06, 14.97it/s, est. speed input: 9190.03 toks/s, output: 1853.76 toks/s][32m [repeated 149x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  79%|███████▊  | 201/256 [00:36<00:06,  8.61it/s, est. speed input: 10676.74 toks/s, output: 2431.49 toks/s][32m [repeated 127x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  91%|█████████▏| 234/256 [00:40<00:09,  2.23it/s, est. speed input: 11819.99 toks/s, output: 3003.05 toks/s]
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  90%|████████▉ | 230/256 [00:42<00:05,  4.36it/s, est. speed input: 11189.86 toks/s, output: 2919.29 toks/s][32m [repeated 63x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  95%|█████████▍| 242/256 [00:45<00:11,  1.21it/s, est. speed input: 11007.45 toks/s, output: 2929.95 toks/s][32m [repeated 24x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  91%|█████████ | 233/256 [00:40<00:05,  4.15it/s, est. speed input: 11849.57 toks/s, output: 2867.46 toks/s][32m [repeated 17x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  97%|█████████▋| 249/256 [00:50<00:05,  1.22it/s, est. speed input: 10443.10 toks/s, output: 2908.72 toks/s][32m [repeated 31x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  95%|█████████▍| 242/256 [00:47<00:12,  1.10it/s, est. speed input: 10530.23 toks/s, output: 2752.79 toks/s][32m [repeated 22x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  98%|█████████▊| 250/256 [01:01<00:15,  2.52s/it, est. speed input: 8424.06 toks/s, output: 2430.87 toks/s][32m [repeated 12x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  99%|█████████▉| 254/256 [01:05<00:02,  1.25s/it, est. speed input: 8127.55 toks/s, output: 2551.02 toks/s]
Processed prompts: 100%|██████████| 256/256 [01:05<00:00,  3.91it/s, est. speed input: 8167.35 toks/s, output: 2674.83 toks/s]
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  99%|█████████▉| 253/256 [01:05<00:07,  2.50s/it, est. speed input: 7968.43 toks/s, output: 2523.33 toks/s][32m [repeated 11x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts: 100%|██████████| 256/256 [01:06<00:00,  1.15s/it, est. speed input: 8138.47 toks/s, output: 2761.27 toks/s]
Processed prompts: 100%|██████████| 256/256 [01:06<00:00,  3.83it/s, est. speed input: 8138.47 toks/s, output: 2761.27 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][32m [repeated 4x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  98%|█████████▊| 251/256 [01:04<00:10,  2.11s/it, est. speed input: 8111.31 toks/s, output: 2402.69 toks/s][32m [repeated 4x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:   0%|          | 1/256 [00:10<44:07, 10.38s/it, est. speed input: 225.22 toks/s, output: 1.93 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts: 100%|██████████| 256/256 [01:06<00:00,  3.87it/s, est. speed input: 8092.03 toks/s, output: 2663.48 toks/s][32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:   1%|          | 2/256 [00:15<31:09,  7.36s/it, est. speed input: 217.28 toks/s, output: 2.50 toks/s][32m [repeated 9x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  11%|█         | 27/256 [00:20<00:51,  4.41it/s, est. speed input: 2506.91 toks/s, output: 131.15 toks/s][32m [repeated 53x across cluster][0m
[36m(LLMRayActor pid=1115134)[0m 
Processed prompts:  22%|██▏       | 57/256 [00:25<00:20,  9.60it/s, est. speed input: 3843.69 toks/s, output: 389.18 toks/s][32m [repeated 92x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  53%|█████▎    | 136/256 [00:30<00:08, 13.94it/s, est. speed input: 7623.18 toks/s, output: 1379.07 toks/s]
Processed prompts:  54%|█████▍    | 139/256 [00:30<00:07, 16.39it/s, est. speed input: 7762.35 toks/s, output: 1425.30 toks/s]
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  54%|█████▎    | 137/256 [00:30<00:06, 19.44it/s, est. speed input: 7586.24 toks/s, output: 1386.58 toks/s][32m [repeated 127x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  60%|█████▉    | 153/256 [00:33<00:08, 11.55it/s, est. speed input: 8636.71 toks/s, output: 1475.84 toks/s][32m [repeated 143x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  75%|███████▌  | 193/256 [00:38<00:10,  5.81it/s, est. speed input: 9773.78 toks/s, output: 1967.67 toks/s][32m [repeated 100x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts:  92%|█████████▏| 235/256 [00:43<00:05,  3.97it/s, est. speed input: 10325.35 toks/s, output: 2681.02 toks/s]
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts:  89%|████████▉ | 228/256 [00:40<00:05,  5.26it/s, est. speed input: 10930.22 toks/s, output: 2676.26 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:40<00:03,  6.91it/s, est. speed input: 11084.04 toks/s, output: 2720.15 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  89%|████████▉ | 228/256 [00:43<00:03,  7.74it/s, est. speed input: 10712.40 toks/s, output: 2482.34 toks/s][32m [repeated 69x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts:  95%|█████████▍| 242/256 [00:49<00:09,  1.42it/s, est. speed input: 9583.18 toks/s, output: 2653.07 toks/s][32m [repeated 35x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  83%|████████▎ | 212/256 [00:41<00:05,  7.71it/s, est. speed input: 9854.03 toks/s, output: 2293.88 toks/s][32m [repeated 22x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  97%|█████████▋| 248/256 [00:51<00:03,  2.18it/s, est. speed input: 10235.66 toks/s, output: 2675.07 toks/s][32m [repeated 26x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  91%|█████████ | 233/256 [00:47<00:10,  2.13it/s, est. speed input: 10059.49 toks/s, output: 2577.58 toks/s][32m [repeated 15x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  93%|█████████▎| 237/256 [00:49<00:09,  1.94it/s, est. speed input: 9865.43 toks/s, output: 2594.95 toks/s][32m [repeated 9x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  98%|█████████▊| 251/256 [01:02<00:11,  2.29s/it, est. speed input: 8563.04 toks/s, output: 2339.40 toks/s][32m [repeated 20x across cluster][0m
[36m(LLMRayActor pid=1115131)[0m 
Processed prompts: 100%|██████████| 256/256 [01:06<00:00,  2.50s/it, est. speed input: 7606.53 toks/s, output: 2374.94 toks/s]
Processed prompts: 100%|██████████| 256/256 [01:06<00:00,  3.83it/s, est. speed input: 7606.53 toks/s, output: 2374.94 toks/s]
[36m(LLMRayActor pid=1115135)[0m 
Processed prompts: 100%|█████████▉| 255/256 [01:06<00:03,  4.00s/it, est. speed input: 7549.62 toks/s, output: 2274.85 toks/s][32m [repeated 9x across cluster][0m
[36m(LLMRayActor pid=1115132)[0m 
Processed prompts: 100%|█████████▉| 255/256 [01:14<00:02,  2.08s/it, est. speed input: 6862.96 toks/s, output: 2298.14 toks/s]
Processed prompts: 100%|██████████| 256/256 [01:14<00:00,  3.45it/s, est. speed input: 6865.31 toks/s, output: 2350.61 toks/s]
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts:  98%|█████████▊| 252/256 [01:13<00:19,  4.90s/it, est. speed input: 7270.70 toks/s, output: 2037.92 toks/s][32m [repeated 8x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m 
Processed prompts: 100%|█████████▉| 255/256 [01:13<00:02,  2.20s/it, est. speed input: 7398.48 toks/s, output: 2200.54 toks/s]
Processed prompts: 100%|██████████| 256/256 [01:13<00:00,  3.49it/s, est. speed input: 7473.62 toks/s, output: 2256.05 toks/s]
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts:  99%|█████████▉| 253/256 [01:13<00:09,  3.19s/it, est. speed input: 7290.70 toks/s, output: 2286.96 toks/s][32m [repeated 2x across cluster][0m
[36m(LLMRayActor pid=1115133)[0m 
Processed prompts: 100%|█████████▉| 255/256 [01:13<00:01,  1.76s/it, est. speed input: 7406.68 toks/s, output: 2394.64 toks/s]
Processed prompts: 100%|██████████| 256/256 [01:13<00:00,  3.49it/s, est. speed input: 7486.78 toks/s, output: 2447.62 toks/s]
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:59:53 [block_pool.py:264] Successfully reset prefix cache
[36m(generate_samples_remote pid=1114553)[0m [2025-08-10 14:55:42,766] [WARNING] [real_accelerator.py:194:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.
[36m(generate_samples_remote pid=1114553)[0m [2025-08-10 14:55:42,768] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cpu (auto detect)
[36m(generate_samples_remote pid=1114553)[0m {'generator': {'0': '$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.', '1': 'Here are solutions from other agents:\n$responses_str\n\nUsing these responses as additional advice, can you give an updated bullet by bullet answer to the following question:\n$question\n\nPlease reason step by step, and put your final answer within \\boxed{}.'}}[32m [repeated 3x across cluster][0m
[36m(generate_samples_remote pid=1114553)[0m Warning: No outputs found for the agent (generator_3) in round 0.[32m [repeated 3x across cluster][0m
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:59:57 [gpu_worker.py:95] Sleep mode freed 32.43 GiB memory, 13.10 GiB memory is still in use.
[36m(LLMRayActor pid=1115136)[0m INFO 08-10 14:59:57 [executor_base.py:210] It took 3.828537 seconds to fall asleep.
[36m(LLMRayActor pid=1115131)[0m INFO 08-10 15:00:01 [block_pool.py:264] Successfully reset prefix cache[32m [repeated 4x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:   0%|          | 0/128 [00:00<?, ?it/s]
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:   1%|          | 1/128 [00:02<05:11,  2.45s/it]
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:   0%|          | 0/128 [00:00<?, ?it/s][32m [repeated 2x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:   2%|▏         | 3/128 [00:09<07:06,  3.41s/it][32m [repeated 6x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:   5%|▌         | 7/128 [00:15<03:24,  1.69s/it][32m [repeated 12x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:   8%|▊         | 10/128 [00:22<04:57,  2.52s/it][32m [repeated 9x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  11%|█         | 14/128 [00:28<03:17,  1.73s/it][32m [repeated 12x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  13%|█▎        | 17/128 [00:35<04:20,  2.34s/it][32m [repeated 9x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  16%|█▌        | 20/128 [00:41<03:41,  2.05s/it][32m [repeated 9x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  18%|█▊        | 23/128 [00:50<04:56,  2.82s/it][32m [repeated 9x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  20%|██        | 26/128 [00:55<03:32,  2.09s/it][32m [repeated 9x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  23%|██▎       | 29/128 [01:00<02:47,  1.69s/it][32m [repeated 13x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  26%|██▌       | 33/128 [01:06<03:00,  1.90s/it][32m [repeated 7x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  27%|██▋       | 35/128 [01:11<02:42,  1.74s/it][32m [repeated 11x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  30%|██▉       | 38/128 [01:17<03:07,  2.09s/it][32m [repeated 9x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  33%|███▎      | 42/128 [01:23<02:02,  1.43s/it][32m [repeated 12x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  35%|███▌      | 45/128 [01:28<02:11,  1.58s/it][32m [repeated 9x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  38%|███▊      | 48/128 [01:33<02:58,  2.23s/it][32m [repeated 5x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  39%|███▉      | 50/128 [01:38<02:10,  1.68s/it][32m [repeated 12x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  44%|████▍     | 56/128 [01:46<02:40,  2.22s/it][32m [repeated 10x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  48%|████▊     | 61/128 [01:52<01:34,  1.41s/it][32m [repeated 14x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  50%|█████     | 64/128 [02:00<02:29,  2.33s/it][32m [repeated 10x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  52%|█████▏    | 67/128 [02:05<01:56,  1.91s/it][32m [repeated 10x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  55%|█████▌    | 71/128 [02:10<01:30,  1.58s/it][32m [repeated 11x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  57%|█████▋    | 73/128 [02:16<02:09,  2.36s/it][32m [repeated 6x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  60%|██████    | 77/128 [02:22<01:20,  1.59s/it][32m [repeated 12x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  60%|██████    | 77/128 [02:28<02:02,  2.40s/it][32m [repeated 9x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  64%|██████▍   | 82/128 [02:34<01:02,  1.36s/it][32m [repeated 15x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  67%|██████▋   | 86/128 [02:39<00:53,  1.26s/it][32m [repeated 10x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  70%|███████   | 90/128 [02:44<01:06,  1.76s/it][32m [repeated 6x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  72%|███████▏  | 92/128 [02:51<01:00,  1.69s/it][32m [repeated 11x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  75%|███████▌  | 96/128 [02:57<01:24,  2.64s/it][32m [repeated 6x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  77%|███████▋  | 98/128 [03:02<01:16,  2.55s/it][32m [repeated 7x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  79%|███████▉  | 101/128 [03:07<00:54,  2.04s/it][32m [repeated 10x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  80%|████████  | 103/128 [03:13<00:58,  2.34s/it][32m [repeated 5x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  82%|████████▏ | 105/128 [03:19<00:40,  1.75s/it][32m [repeated 11x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  84%|████████▍ | 108/128 [03:24<00:53,  2.67s/it][32m [repeated 5x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  87%|████████▋ | 111/128 [03:30<00:34,  2.01s/it][32m [repeated 8x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  90%|████████▉ | 115/128 [03:35<00:20,  1.61s/it][32m [repeated 12x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience:  91%|█████████▏| 117/128 [03:41<00:26,  2.41s/it]
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  91%|█████████ | 116/128 [03:39<00:28,  2.38s/it][32m [repeated 4x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  93%|█████████▎| 119/128 [03:47<00:21,  2.37s/it][32m [repeated 5x across cluster][0m
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  91%|█████████ | 116/128 [03:43<00:26,  2.18s/it][32m [repeated 2x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  95%|█████████▍| 121/128 [03:52<00:18,  2.68s/it][32m [repeated 6x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  97%|█████████▋| 124/128 [03:58<00:08,  2.07s/it][32m [repeated 10x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
make_experience:  99%|█████████▉| 127/128 [04:03<00:01,  1.83s/it][32m [repeated 9x across cluster][0m
[36m(ActorModelRayActor pid=1115138)[0m 
make_experience: 100%|██████████| 128/128 [04:06<00:00,  2.49s/it]
make_experience: 100%|██████████| 128/128 [04:06<00:00,  1.92s/it]
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience:  99%|█████████▉| 127/128 [04:08<00:02,  2.22s/it][32m [repeated 2x across cluster][0m
[36m(ActorModelRayActor pid=1115137)[0m 
Train epoch [1/1] (actor_generator_3):   0%|          | 0/256 [00:00<?, ?it/s]
[36m(ActorModelRayActor pid=1115139)[0m 
make_experience: 100%|██████████| 128/128 [04:10<00:00,  2.09s/it]
make_experience: 100%|██████████| 128/128 [04:10<00:00,  1.95s/it][32m [repeated 2x across cluster][0m
